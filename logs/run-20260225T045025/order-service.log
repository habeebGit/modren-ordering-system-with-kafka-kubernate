
> order-service@1.0.0 start
> node index.js

[dotenv@17.3.1] injecting env (0) from .env -- tip: âš™ï¸  write to custom object with { processEnv: myObject }
{"level":"WARN","timestamp":"2026-02-25T10:39:31.963Z","logger":"kafkajs","message":"KafkaJS v2.0.0 switched default partitioner. To retain the same partitioning behavior as in previous versions, create the producer with the option \"createPartitioner: Partitioners.LegacyPartitioner\". See the migration guide at https://kafka.js.org/docs/migration-guide-v2.0.0#producer-new-default-partitioner for details. Silence this warning by setting the environment variable \"KAFKAJS_NO_PARTITIONER_WARNING=1\""}
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'Orders'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'Orders' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'Orders' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "userId" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "userId" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "userId" TYPE INTEGER;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "status" DROP NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "status" SET DEFAULT 'Pending';ALTER TABLE "Orders" ALTER COLUMN "status" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'Orders' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'OrderItems'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'OrderItems' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'OrderItems' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "productId" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "productId" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "productId" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "quantity" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" DROP CONSTRAINT "OrderItems_OrderId_fkey"
Executing (default): ALTER TABLE "OrderItems"  ADD FOREIGN KEY ("OrderId") REFERENCES "Orders" ("id") ON DELETE SET NULL ON UPDATE CASCADE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'OrderItems' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'ProcessedEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'ProcessedEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'ProcessedEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'ProcessedEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'DeadLetterEvents'
Executing (default): CREATE TABLE IF NOT EXISTS "DeadLetterEvents" ("id" VARCHAR(255) , "eventType" VARCHAR(255), "payload" JSON, "errorMessage" TEXT, "createdAt" TIMESTAMP WITH TIME ZONE, "updatedAt" TIMESTAMP WITH TIME ZONE NOT NULL, PRIMARY KEY ("id"));
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'DeadLetterEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
{"level":"ERROR","timestamp":"2026-02-25T10:39:32.122Z","logger":"kafkajs","message":"[Connection] Connection error: connect ECONNREFUSED 172.18.0.7:9092","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: connect ECONNREFUSED 172.18.0.7:9092\n    at TCPConnectWrap.afterConnect [as oncomplete] (node:net:1555:16)"}
{"level":"ERROR","timestamp":"2026-02-25T10:39:32.123Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: connect ECONNREFUSED 172.18.0.7:9092","retryCount":0,"retryTime":277}
{"level":"ERROR","timestamp":"2026-02-25T10:39:32.402Z","logger":"kafkajs","message":"[Connection] Connection error: connect ECONNREFUSED 172.18.0.7:9092","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: connect ECONNREFUSED 172.18.0.7:9092\n    at TCPConnectWrap.afterConnect [as oncomplete] (node:net:1555:16)"}
{"level":"ERROR","timestamp":"2026-02-25T10:39:32.403Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: connect ECONNREFUSED 172.18.0.7:9092","retryCount":1,"retryTime":552}
{"level":"ERROR","timestamp":"2026-02-25T10:39:32.956Z","logger":"kafkajs","message":"[Connection] Connection error: connect ECONNREFUSED 172.18.0.7:9092","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: connect ECONNREFUSED 172.18.0.7:9092\n    at TCPConnectWrap.afterConnect [as oncomplete] (node:net:1555:16)"}
{"level":"ERROR","timestamp":"2026-02-25T10:39:32.956Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: connect ECONNREFUSED 172.18.0.7:9092","retryCount":2,"retryTime":1256}
{"level":"ERROR","timestamp":"2026-02-25T10:39:34.213Z","logger":"kafkajs","message":"[Connection] Connection error: connect ECONNREFUSED 172.18.0.7:9092","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: connect ECONNREFUSED 172.18.0.7:9092\n    at TCPConnectWrap.afterConnect [as oncomplete] (node:net:1555:16)"}
{"level":"ERROR","timestamp":"2026-02-25T10:39:34.214Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: connect ECONNREFUSED 172.18.0.7:9092","retryCount":3,"retryTime":2892}
{"level":"ERROR","timestamp":"2026-02-25T10:39:37.120Z","logger":"kafkajs","message":"[Connection] Connection error: connect ECONNREFUSED 172.18.0.7:9092","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: connect ECONNREFUSED 172.18.0.7:9092\n    at TCPConnectWrap.afterConnect [as oncomplete] (node:net:1555:16)"}
{"level":"ERROR","timestamp":"2026-02-25T10:39:37.122Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: connect ECONNREFUSED 172.18.0.7:9092","retryCount":4,"retryTime":6600}
{"level":"ERROR","timestamp":"2026-02-25T10:39:43.750Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:39:43.752Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":12032}
{"error":"Connection error: getaddrinfo ENOTFOUND kafka","level":"error","message":"Failed to connect Kafka producer on startup","timestamp":"2026-02-25T10:39:43.753Z"}
Server is running on port 3001
{"level":"ERROR","timestamp":"2026-02-25T10:39:43.770Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:39:43.771Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":325}
{"level":"ERROR","timestamp":"2026-02-25T10:39:44.107Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:39:44.108Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":624}
{"level":"ERROR","timestamp":"2026-02-25T10:39:44.738Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:39:44.739Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":1342}
{"level":"ERROR","timestamp":"2026-02-25T10:39:46.087Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:39:46.087Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":2826}
{"level":"ERROR","timestamp":"2026-02-25T10:39:48.925Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:39:48.926Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":5386}
{"level":"info","message":"::ffff:172.18.0.2 - - [25/Feb/2026:10:39:53 +0000] \"GET /metrics HTTP/1.1\" 200 - \"-\" \"Prometheus/3.7.1\"","timestamp":"2026-02-25T10:39:53.544Z"}
{"level":"ERROR","timestamp":"2026-02-25T10:39:54.323Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:39:54.324Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":11688}
node:internal/process/promises:288
            triggerUncaughtException(err, true /* fromPromise */);
            ^

KafkaJSNonRetriableError
  Caused by: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
    at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
    ... 3 lines matching cause stack trace ...
    at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
  name: 'KafkaJSNumberOfRetriesExceeded',
  retriable: false,
  helpUrl: undefined,
  retryCount: 5,
  retryTime: 11688,
  [cause]: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
      at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
      at Socket.emit (node:events:517:28)
      at emitErrorNT (node:internal/streams/destroy:151:8)
      at emitErrorCloseNT (node:internal/streams/destroy:116:3)
      at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
    retriable: true,
    helpUrl: undefined,
    broker: 'kafka:9092',
    code: 'ENOTFOUND',
    [cause]: undefined
  }
}

Node.js v18.20.8
npm notice
npm notice New major version of npm available! 10.8.2 -> 11.10.1
npm notice Changelog: https://github.com/npm/cli/releases/tag/v11.10.1
npm notice To update run: npm install -g npm@11.10.1
npm notice

> order-service@1.0.0 start
> node index.js

[dotenv@17.3.1] injecting env (0) from .env -- tip: ðŸ¤– agentic secret storage: https://dotenvx.com/as2
{"level":"WARN","timestamp":"2026-02-25T10:39:55.066Z","logger":"kafkajs","message":"KafkaJS v2.0.0 switched default partitioner. To retain the same partitioning behavior as in previous versions, create the producer with the option \"createPartitioner: Partitioners.LegacyPartitioner\". See the migration guide at https://kafka.js.org/docs/migration-guide-v2.0.0#producer-new-default-partitioner for details. Silence this warning by setting the environment variable \"KAFKAJS_NO_PARTITIONER_WARNING=1\""}
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'Orders'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'Orders' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'Orders' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "userId" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "userId" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "userId" TYPE INTEGER;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "status" DROP NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "status" SET DEFAULT 'Pending';ALTER TABLE "Orders" ALTER COLUMN "status" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'Orders' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'OrderItems'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'OrderItems' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'OrderItems' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "productId" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "productId" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "productId" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "quantity" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" DROP CONSTRAINT "OrderItems_OrderId_fkey"
Executing (default): ALTER TABLE "OrderItems"  ADD FOREIGN KEY ("OrderId") REFERENCES "Orders" ("id") ON DELETE SET NULL ON UPDATE CASCADE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'OrderItems' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'ProcessedEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'ProcessedEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'ProcessedEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'ProcessedEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'DeadLetterEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'DeadLetterEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'DeadLetterEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" TYPE JSON;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" TYPE TEXT;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'DeadLetterEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
{"level":"ERROR","timestamp":"2026-02-25T10:39:55.147Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:39:55.147Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":348}
{"level":"ERROR","timestamp":"2026-02-25T10:39:55.507Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:39:55.509Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":580}
{"level":"ERROR","timestamp":"2026-02-25T10:39:56.098Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:39:56.098Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":1310}
{"level":"ERROR","timestamp":"2026-02-25T10:39:57.420Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:39:57.422Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":2886}
{"level":"ERROR","timestamp":"2026-02-25T10:40:00.320Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:40:00.321Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":5854}
{"level":"ERROR","timestamp":"2026-02-25T10:40:06.183Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:40:06.184Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":12248}
{"error":"Connection error: getaddrinfo ENOTFOUND kafka","level":"error","message":"Failed to connect Kafka producer on startup","timestamp":"2026-02-25T10:40:06.185Z"}
Server is running on port 3001
{"level":"ERROR","timestamp":"2026-02-25T10:40:06.192Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:40:06.193Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":253}
{"level":"ERROR","timestamp":"2026-02-25T10:40:06.452Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:40:06.453Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":474}
{"level":"ERROR","timestamp":"2026-02-25T10:40:06.936Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:40:06.936Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":928}
{"level":"ERROR","timestamp":"2026-02-25T10:40:07.876Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:40:07.876Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":1644}
{"level":"info","message":"::ffff:172.18.0.2 - - [25/Feb/2026:10:40:08 +0000] \"GET /metrics HTTP/1.1\" 200 - \"-\" \"Prometheus/3.7.1\"","timestamp":"2026-02-25T10:40:08.548Z"}
{"level":"ERROR","timestamp":"2026-02-25T10:40:09.527Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:40:09.528Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":3506}
{"level":"ERROR","timestamp":"2026-02-25T10:40:13.047Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:40:13.048Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":7524}
node:internal/process/promises:288
            triggerUncaughtException(err, true /* fromPromise */);
            ^

KafkaJSNonRetriableError
  Caused by: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
    at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
    ... 3 lines matching cause stack trace ...
    at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
  name: 'KafkaJSNumberOfRetriesExceeded',
  retriable: false,
  helpUrl: undefined,
  retryCount: 5,
  retryTime: 7524,
  [cause]: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
      at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
      at Socket.emit (node:events:517:28)
      at emitErrorNT (node:internal/streams/destroy:151:8)
      at emitErrorCloseNT (node:internal/streams/destroy:116:3)
      at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
    retriable: true,
    helpUrl: undefined,
    broker: 'kafka:9092',
    code: 'ENOTFOUND',
    [cause]: undefined
  }
}

Node.js v18.20.8

> order-service@1.0.0 start
> node index.js

[dotenv@17.3.1] injecting env (0) from .env -- tip: ðŸ¤– agentic secret storage: https://dotenvx.com/as2
{"level":"WARN","timestamp":"2026-02-25T10:40:13.669Z","logger":"kafkajs","message":"KafkaJS v2.0.0 switched default partitioner. To retain the same partitioning behavior as in previous versions, create the producer with the option \"createPartitioner: Partitioners.LegacyPartitioner\". See the migration guide at https://kafka.js.org/docs/migration-guide-v2.0.0#producer-new-default-partitioner for details. Silence this warning by setting the environment variable \"KAFKAJS_NO_PARTITIONER_WARNING=1\""}
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'Orders'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'Orders' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'Orders' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "userId" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "userId" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "userId" TYPE INTEGER;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "status" DROP NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "status" SET DEFAULT 'Pending';ALTER TABLE "Orders" ALTER COLUMN "status" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'Orders' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'OrderItems'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'OrderItems' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'OrderItems' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "productId" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "productId" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "productId" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "quantity" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" DROP CONSTRAINT "OrderItems_OrderId_fkey"
Executing (default): ALTER TABLE "OrderItems"  ADD FOREIGN KEY ("OrderId") REFERENCES "Orders" ("id") ON DELETE SET NULL ON UPDATE CASCADE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'OrderItems' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'ProcessedEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'ProcessedEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'ProcessedEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'ProcessedEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'DeadLetterEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'DeadLetterEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'DeadLetterEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" TYPE JSON;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" TYPE TEXT;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'DeadLetterEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
{"level":"ERROR","timestamp":"2026-02-25T10:40:13.748Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:40:13.749Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":277}
{"level":"ERROR","timestamp":"2026-02-25T10:40:14.031Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:40:14.032Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":450}
{"level":"ERROR","timestamp":"2026-02-25T10:40:14.488Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:40:14.488Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":958}
{"level":"ERROR","timestamp":"2026-02-25T10:40:15.463Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:40:15.466Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":1850}
{"level":"ERROR","timestamp":"2026-02-25T10:40:17.326Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:40:17.327Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":3934}
{"level":"ERROR","timestamp":"2026-02-25T10:40:21.276Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:40:21.279Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":9220}
{"error":"Connection error: getaddrinfo ENOTFOUND kafka","level":"error","message":"Failed to connect Kafka producer on startup","timestamp":"2026-02-25T10:40:21.283Z"}
Server is running on port 3001
{"level":"ERROR","timestamp":"2026-02-25T10:40:21.301Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:40:21.301Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":328}
{"level":"ERROR","timestamp":"2026-02-25T10:40:21.643Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:40:21.644Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":628}
{"level":"ERROR","timestamp":"2026-02-25T10:40:22.282Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:40:22.283Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":1324}
{"level":"info","message":"::ffff:172.18.0.2 - - [25/Feb/2026:10:40:23 +0000] \"GET /metrics HTTP/1.1\" 200 - \"-\" \"Prometheus/3.7.1\"","timestamp":"2026-02-25T10:40:23.550Z"}
{"level":"ERROR","timestamp":"2026-02-25T10:40:23.618Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:40:23.619Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":3000}
{"level":"ERROR","timestamp":"2026-02-25T10:40:26.633Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:40:26.635Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":6500}
{"level":"ERROR","timestamp":"2026-02-25T10:40:33.147Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:40:33.148Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":15462}
node:internal/process/promises:288
            triggerUncaughtException(err, true /* fromPromise */);
            ^

KafkaJSNonRetriableError
  Caused by: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
    at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
    ... 3 lines matching cause stack trace ...
    at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
  name: 'KafkaJSNumberOfRetriesExceeded',
  retriable: false,
  helpUrl: undefined,
  retryCount: 5,
  retryTime: 15462,
  [cause]: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
      at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
      at Socket.emit (node:events:517:28)
      at emitErrorNT (node:internal/streams/destroy:151:8)
      at emitErrorCloseNT (node:internal/streams/destroy:116:3)
      at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
    retriable: true,
    helpUrl: undefined,
    broker: 'kafka:9092',
    code: 'ENOTFOUND',
    [cause]: undefined
  }
}

Node.js v18.20.8

> order-service@1.0.0 start
> node index.js

[dotenv@17.3.1] injecting env (0) from .env -- tip: âš™ï¸  suppress all logs with { quiet: true }
{"level":"WARN","timestamp":"2026-02-25T10:40:33.854Z","logger":"kafkajs","message":"KafkaJS v2.0.0 switched default partitioner. To retain the same partitioning behavior as in previous versions, create the producer with the option \"createPartitioner: Partitioners.LegacyPartitioner\". See the migration guide at https://kafka.js.org/docs/migration-guide-v2.0.0#producer-new-default-partitioner for details. Silence this warning by setting the environment variable \"KAFKAJS_NO_PARTITIONER_WARNING=1\""}
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'Orders'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'Orders' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'Orders' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "userId" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "userId" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "userId" TYPE INTEGER;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "status" DROP NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "status" SET DEFAULT 'Pending';ALTER TABLE "Orders" ALTER COLUMN "status" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'Orders' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'OrderItems'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'OrderItems' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'OrderItems' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "productId" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "productId" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "productId" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "quantity" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" DROP CONSTRAINT "OrderItems_OrderId_fkey"
Executing (default): ALTER TABLE "OrderItems"  ADD FOREIGN KEY ("OrderId") REFERENCES "Orders" ("id") ON DELETE SET NULL ON UPDATE CASCADE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'OrderItems' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'ProcessedEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'ProcessedEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'ProcessedEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'ProcessedEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'DeadLetterEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'DeadLetterEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'DeadLetterEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" TYPE JSON;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" TYPE TEXT;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'DeadLetterEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
{"level":"ERROR","timestamp":"2026-02-25T10:40:33.937Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:40:33.937Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":284}
{"level":"ERROR","timestamp":"2026-02-25T10:40:34.239Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:40:34.240Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":612}
{"level":"ERROR","timestamp":"2026-02-25T10:40:34.863Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:40:34.864Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":1386}
{"level":"ERROR","timestamp":"2026-02-25T10:40:36.297Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:40:36.302Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":2254}
{"level":"ERROR","timestamp":"2026-02-25T10:40:38.567Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:40:38.568Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":5060}
{"level":"ERROR","timestamp":"2026-02-25T10:40:43.642Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:40:43.644Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":8706}
{"error":"Connection error: getaddrinfo ENOTFOUND kafka","level":"error","message":"Failed to connect Kafka producer on startup","timestamp":"2026-02-25T10:40:43.647Z"}
Server is running on port 3001
{"level":"ERROR","timestamp":"2026-02-25T10:40:43.663Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:40:43.663Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":258}
{"level":"ERROR","timestamp":"2026-02-25T10:40:43.937Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:40:43.938Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":448}
{"level":"ERROR","timestamp":"2026-02-25T10:40:44.396Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:40:44.397Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":894}
{"level":"ERROR","timestamp":"2026-02-25T10:40:45.304Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:40:45.305Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":2112}
{"level":"ERROR","timestamp":"2026-02-25T10:40:47.431Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:40:47.432Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":4312}
{"level":"ERROR","timestamp":"2026-02-25T10:40:51.754Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:40:51.755Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":6906}
node:internal/process/promises:288
            triggerUncaughtException(err, true /* fromPromise */);
            ^

KafkaJSNonRetriableError
  Caused by: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
    at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
    ... 3 lines matching cause stack trace ...
    at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
  name: 'KafkaJSNumberOfRetriesExceeded',
  retriable: false,
  helpUrl: undefined,
  retryCount: 5,
  retryTime: 6906,
  [cause]: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
      at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
      at Socket.emit (node:events:517:28)
      at emitErrorNT (node:internal/streams/destroy:151:8)
      at emitErrorCloseNT (node:internal/streams/destroy:116:3)
      at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
    retriable: true,
    helpUrl: undefined,
    broker: 'kafka:9092',
    code: 'ENOTFOUND',
    [cause]: undefined
  }
}

Node.js v18.20.8

> order-service@1.0.0 start
> node index.js

[dotenv@17.3.1] injecting env (0) from .env -- tip: ðŸ” prevent committing .env to code: https://dotenvx.com/precommit
{"level":"WARN","timestamp":"2026-02-25T10:40:52.426Z","logger":"kafkajs","message":"KafkaJS v2.0.0 switched default partitioner. To retain the same partitioning behavior as in previous versions, create the producer with the option \"createPartitioner: Partitioners.LegacyPartitioner\". See the migration guide at https://kafka.js.org/docs/migration-guide-v2.0.0#producer-new-default-partitioner for details. Silence this warning by setting the environment variable \"KAFKAJS_NO_PARTITIONER_WARNING=1\""}
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'Orders'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'Orders' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'Orders' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "userId" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "userId" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "userId" TYPE INTEGER;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "status" DROP NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "status" SET DEFAULT 'Pending';ALTER TABLE "Orders" ALTER COLUMN "status" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'Orders' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'OrderItems'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'OrderItems' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'OrderItems' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "productId" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "productId" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "productId" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "quantity" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" DROP CONSTRAINT "OrderItems_OrderId_fkey"
Executing (default): ALTER TABLE "OrderItems"  ADD FOREIGN KEY ("OrderId") REFERENCES "Orders" ("id") ON DELETE SET NULL ON UPDATE CASCADE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'OrderItems' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'ProcessedEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'ProcessedEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'ProcessedEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'ProcessedEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'DeadLetterEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'DeadLetterEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'DeadLetterEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" TYPE JSON;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" TYPE TEXT;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'DeadLetterEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
{"level":"ERROR","timestamp":"2026-02-25T10:40:52.529Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:40:52.529Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":356}
{"level":"ERROR","timestamp":"2026-02-25T10:40:52.895Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:40:52.897Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":852}
{"level":"ERROR","timestamp":"2026-02-25T10:40:53.761Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:40:53.762Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":1460}
{"level":"ERROR","timestamp":"2026-02-25T10:40:55.236Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:40:55.238Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":2506}
{"level":"ERROR","timestamp":"2026-02-25T10:40:57.754Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:40:57.755Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":4244}
{"level":"ERROR","timestamp":"2026-02-25T10:41:02.011Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:41:02.013Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":9646}
{"error":"Connection error: getaddrinfo ENOTFOUND kafka","level":"error","message":"Failed to connect Kafka producer on startup","timestamp":"2026-02-25T10:41:02.015Z"}
Server is running on port 3001
{"level":"ERROR","timestamp":"2026-02-25T10:41:02.031Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:41:02.031Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":319}
{"level":"ERROR","timestamp":"2026-02-25T10:41:02.360Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:41:02.361Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":690}
{"level":"ERROR","timestamp":"2026-02-25T10:41:03.057Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:41:03.057Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":1498}
{"level":"ERROR","timestamp":"2026-02-25T10:41:04.569Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:41:04.570Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":2876}
{"level":"ERROR","timestamp":"2026-02-25T10:41:07.467Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:41:07.468Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":4910}
{"level":"info","message":"::ffff:172.18.0.2 - - [25/Feb/2026:10:41:08 +0000] \"GET /metrics HTTP/1.1\" 200 - \"-\" \"Prometheus/3.7.1\"","timestamp":"2026-02-25T10:41:08.543Z"}
{"level":"ERROR","timestamp":"2026-02-25T10:41:12.390Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:41:12.391Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":11686}
node:internal/process/promises:288
            triggerUncaughtException(err, true /* fromPromise */);
            ^

KafkaJSNonRetriableError
  Caused by: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
    at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
    ... 3 lines matching cause stack trace ...
    at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
  name: 'KafkaJSNumberOfRetriesExceeded',
  retriable: false,
  helpUrl: undefined,
  retryCount: 5,
  retryTime: 11686,
  [cause]: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
      at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
      at Socket.emit (node:events:517:28)
      at emitErrorNT (node:internal/streams/destroy:151:8)
      at emitErrorCloseNT (node:internal/streams/destroy:116:3)
      at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
    retriable: true,
    helpUrl: undefined,
    broker: 'kafka:9092',
    code: 'ENOTFOUND',
    [cause]: undefined
  }
}

Node.js v18.20.8

> order-service@1.0.0 start
> node index.js

[dotenv@17.3.1] injecting env (0) from .env -- tip: âš™ï¸  enable debug logging with { debug: true }
{"level":"WARN","timestamp":"2026-02-25T10:41:13.034Z","logger":"kafkajs","message":"KafkaJS v2.0.0 switched default partitioner. To retain the same partitioning behavior as in previous versions, create the producer with the option \"createPartitioner: Partitioners.LegacyPartitioner\". See the migration guide at https://kafka.js.org/docs/migration-guide-v2.0.0#producer-new-default-partitioner for details. Silence this warning by setting the environment variable \"KAFKAJS_NO_PARTITIONER_WARNING=1\""}
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'Orders'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'Orders' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'Orders' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "userId" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "userId" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "userId" TYPE INTEGER;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "status" DROP NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "status" SET DEFAULT 'Pending';ALTER TABLE "Orders" ALTER COLUMN "status" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'Orders' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'OrderItems'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'OrderItems' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'OrderItems' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "productId" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "productId" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "productId" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "quantity" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" DROP CONSTRAINT "OrderItems_OrderId_fkey"
Executing (default): ALTER TABLE "OrderItems"  ADD FOREIGN KEY ("OrderId") REFERENCES "Orders" ("id") ON DELETE SET NULL ON UPDATE CASCADE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'OrderItems' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'ProcessedEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'ProcessedEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'ProcessedEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'ProcessedEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'DeadLetterEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'DeadLetterEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'DeadLetterEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" TYPE JSON;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" TYPE TEXT;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'DeadLetterEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
{"level":"ERROR","timestamp":"2026-02-25T10:41:13.113Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:41:13.114Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":330}
{"level":"ERROR","timestamp":"2026-02-25T10:41:13.460Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:41:13.462Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":746}
{"level":"ERROR","timestamp":"2026-02-25T10:41:14.224Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:41:14.226Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":1356}
{"level":"ERROR","timestamp":"2026-02-25T10:41:15.595Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:41:15.598Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":2878}
{"level":"ERROR","timestamp":"2026-02-25T10:41:18.488Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:41:18.489Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":6754}
{"level":"ERROR","timestamp":"2026-02-25T10:41:25.259Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:41:25.261Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":15522}
{"error":"Connection error: getaddrinfo ENOTFOUND kafka","level":"error","message":"Failed to connect Kafka producer on startup","timestamp":"2026-02-25T10:41:25.264Z"}
Server is running on port 3001
{"level":"ERROR","timestamp":"2026-02-25T10:41:25.279Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:41:25.279Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":347}
{"level":"ERROR","timestamp":"2026-02-25T10:41:25.635Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:41:25.636Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":638}
{"level":"ERROR","timestamp":"2026-02-25T10:41:26.282Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:41:26.284Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":1438}
{"level":"ERROR","timestamp":"2026-02-25T10:41:27.735Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:41:27.736Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":2542}
{"level":"ERROR","timestamp":"2026-02-25T10:41:30.293Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:41:30.295Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":5016}
{"level":"ERROR","timestamp":"2026-02-25T10:41:35.328Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:41:35.329Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":11668}
node:internal/process/promises:288
            triggerUncaughtException(err, true /* fromPromise */);
            ^

KafkaJSNonRetriableError
  Caused by: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
    at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
    ... 3 lines matching cause stack trace ...
    at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
  name: 'KafkaJSNumberOfRetriesExceeded',
  retriable: false,
  helpUrl: undefined,
  retryCount: 5,
  retryTime: 11668,
  [cause]: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
      at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
      at Socket.emit (node:events:517:28)
      at emitErrorNT (node:internal/streams/destroy:151:8)
      at emitErrorCloseNT (node:internal/streams/destroy:116:3)
      at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
    retriable: true,
    helpUrl: undefined,
    broker: 'kafka:9092',
    code: 'ENOTFOUND',
    [cause]: undefined
  }
}

Node.js v18.20.8

> order-service@1.0.0 start
> node index.js

[dotenv@17.3.1] injecting env (0) from .env -- tip: ðŸ” encrypt with Dotenvx: https://dotenvx.com
{"level":"WARN","timestamp":"2026-02-25T10:41:36.233Z","logger":"kafkajs","message":"KafkaJS v2.0.0 switched default partitioner. To retain the same partitioning behavior as in previous versions, create the producer with the option \"createPartitioner: Partitioners.LegacyPartitioner\". See the migration guide at https://kafka.js.org/docs/migration-guide-v2.0.0#producer-new-default-partitioner for details. Silence this warning by setting the environment variable \"KAFKAJS_NO_PARTITIONER_WARNING=1\""}
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'Orders'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'Orders' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'Orders' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "userId" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "userId" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "userId" TYPE INTEGER;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "status" DROP NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "status" SET DEFAULT 'Pending';ALTER TABLE "Orders" ALTER COLUMN "status" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'Orders' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'OrderItems'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'OrderItems' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'OrderItems' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "productId" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "productId" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "productId" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "quantity" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" DROP CONSTRAINT "OrderItems_OrderId_fkey"
Executing (default): ALTER TABLE "OrderItems"  ADD FOREIGN KEY ("OrderId") REFERENCES "Orders" ("id") ON DELETE SET NULL ON UPDATE CASCADE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'OrderItems' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'ProcessedEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'ProcessedEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'ProcessedEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'ProcessedEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'DeadLetterEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'DeadLetterEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'DeadLetterEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" TYPE JSON;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" TYPE TEXT;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'DeadLetterEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
{"level":"ERROR","timestamp":"2026-02-25T10:41:36.321Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:41:36.321Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":280}
{"level":"ERROR","timestamp":"2026-02-25T10:41:36.616Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:41:36.618Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":546}
{"level":"ERROR","timestamp":"2026-02-25T10:41:37.183Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:41:37.183Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":1148}
{"level":"ERROR","timestamp":"2026-02-25T10:41:38.344Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:41:38.346Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":1954}
{"level":"ERROR","timestamp":"2026-02-25T10:41:40.319Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:41:40.323Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":3846}
{"level":"ERROR","timestamp":"2026-02-25T10:41:44.182Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:41:44.183Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":6308}
{"error":"Connection error: getaddrinfo ENOTFOUND kafka","level":"error","message":"Failed to connect Kafka producer on startup","timestamp":"2026-02-25T10:41:44.185Z"}
Server is running on port 3001
{"level":"ERROR","timestamp":"2026-02-25T10:41:44.203Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:41:44.203Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":267}
{"level":"ERROR","timestamp":"2026-02-25T10:41:44.482Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:41:44.483Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":612}
{"level":"ERROR","timestamp":"2026-02-25T10:41:45.106Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:41:45.107Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":1086}
{"level":"ERROR","timestamp":"2026-02-25T10:41:46.200Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:41:46.200Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":1834}
{"level":"ERROR","timestamp":"2026-02-25T10:41:48.048Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:41:48.049Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":3974}
{"level":"ERROR","timestamp":"2026-02-25T10:41:52.041Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:41:52.043Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":7834}
node:internal/process/promises:288
            triggerUncaughtException(err, true /* fromPromise */);
            ^

KafkaJSNonRetriableError
  Caused by: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
    at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
    ... 3 lines matching cause stack trace ...
    at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
  name: 'KafkaJSNumberOfRetriesExceeded',
  retriable: false,
  helpUrl: undefined,
  retryCount: 5,
  retryTime: 7834,
  [cause]: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
      at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
      at Socket.emit (node:events:517:28)
      at emitErrorNT (node:internal/streams/destroy:151:8)
      at emitErrorCloseNT (node:internal/streams/destroy:116:3)
      at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
    retriable: true,
    helpUrl: undefined,
    broker: 'kafka:9092',
    code: 'ENOTFOUND',
    [cause]: undefined
  }
}

Node.js v18.20.8

> order-service@1.0.0 start
> node index.js

[dotenv@17.3.1] injecting env (0) from .env -- tip: âš™ï¸  suppress all logs with { quiet: true }
{"level":"WARN","timestamp":"2026-02-25T10:41:52.825Z","logger":"kafkajs","message":"KafkaJS v2.0.0 switched default partitioner. To retain the same partitioning behavior as in previous versions, create the producer with the option \"createPartitioner: Partitioners.LegacyPartitioner\". See the migration guide at https://kafka.js.org/docs/migration-guide-v2.0.0#producer-new-default-partitioner for details. Silence this warning by setting the environment variable \"KAFKAJS_NO_PARTITIONER_WARNING=1\""}
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'Orders'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'Orders' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'Orders' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "userId" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "userId" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "userId" TYPE INTEGER;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "status" DROP NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "status" SET DEFAULT 'Pending';ALTER TABLE "Orders" ALTER COLUMN "status" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'Orders' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'OrderItems'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'OrderItems' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'OrderItems' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "productId" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "productId" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "productId" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "quantity" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" DROP CONSTRAINT "OrderItems_OrderId_fkey"
Executing (default): ALTER TABLE "OrderItems"  ADD FOREIGN KEY ("OrderId") REFERENCES "Orders" ("id") ON DELETE SET NULL ON UPDATE CASCADE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'OrderItems' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'ProcessedEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'ProcessedEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'ProcessedEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'ProcessedEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'DeadLetterEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'DeadLetterEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'DeadLetterEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" TYPE JSON;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" TYPE TEXT;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'DeadLetterEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
{"level":"ERROR","timestamp":"2026-02-25T10:41:52.914Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:41:52.915Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":271}
{"level":"ERROR","timestamp":"2026-02-25T10:41:53.197Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:41:53.199Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":524}
{"level":"ERROR","timestamp":"2026-02-25T10:41:53.735Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:41:53.735Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":994}
{"level":"ERROR","timestamp":"2026-02-25T10:41:54.742Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:41:54.745Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":2340}
{"level":"ERROR","timestamp":"2026-02-25T10:41:57.100Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:41:57.101Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":3796}
{"level":"ERROR","timestamp":"2026-02-25T10:42:00.910Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:42:00.911Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":6542}
{"error":"Connection error: getaddrinfo ENOTFOUND kafka","level":"error","message":"Failed to connect Kafka producer on startup","timestamp":"2026-02-25T10:42:00.915Z"}
Server is running on port 3001
{"level":"ERROR","timestamp":"2026-02-25T10:42:00.931Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:42:00.932Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":344}
{"level":"ERROR","timestamp":"2026-02-25T10:42:01.288Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:42:01.289Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":662}
{"level":"ERROR","timestamp":"2026-02-25T10:42:01.958Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:42:01.959Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":1584}
{"level":"ERROR","timestamp":"2026-02-25T10:42:03.553Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:42:03.554Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":2784}
{"level":"ERROR","timestamp":"2026-02-25T10:42:06.346Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:42:06.346Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":5412}
{"level":"info","message":"::ffff:172.18.0.2 - - [25/Feb/2026:10:42:08 +0000] \"GET /metrics HTTP/1.1\" 200 - \"-\" \"Prometheus/3.7.1\"","timestamp":"2026-02-25T10:42:08.553Z"}
{"level":"ERROR","timestamp":"2026-02-25T10:42:11.771Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:42:11.772Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":12350}
node:internal/process/promises:288
            triggerUncaughtException(err, true /* fromPromise */);
            ^

KafkaJSNonRetriableError
  Caused by: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
    at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
    ... 3 lines matching cause stack trace ...
    at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
  name: 'KafkaJSNumberOfRetriesExceeded',
  retriable: false,
  helpUrl: undefined,
  retryCount: 5,
  retryTime: 12350,
  [cause]: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
      at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
      at Socket.emit (node:events:517:28)
      at emitErrorNT (node:internal/streams/destroy:151:8)
      at emitErrorCloseNT (node:internal/streams/destroy:116:3)
      at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
    retriable: true,
    helpUrl: undefined,
    broker: 'kafka:9092',
    code: 'ENOTFOUND',
    [cause]: undefined
  }
}

Node.js v18.20.8

> order-service@1.0.0 start
> node index.js

[dotenv@17.3.1] injecting env (0) from .env -- tip: ðŸ› ï¸  run anywhere with `dotenvx run -- yourcommand`
{"level":"WARN","timestamp":"2026-02-25T10:42:12.452Z","logger":"kafkajs","message":"KafkaJS v2.0.0 switched default partitioner. To retain the same partitioning behavior as in previous versions, create the producer with the option \"createPartitioner: Partitioners.LegacyPartitioner\". See the migration guide at https://kafka.js.org/docs/migration-guide-v2.0.0#producer-new-default-partitioner for details. Silence this warning by setting the environment variable \"KAFKAJS_NO_PARTITIONER_WARNING=1\""}
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'Orders'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'Orders' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'Orders' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "userId" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "userId" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "userId" TYPE INTEGER;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "status" DROP NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "status" SET DEFAULT 'Pending';ALTER TABLE "Orders" ALTER COLUMN "status" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'Orders' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'OrderItems'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'OrderItems' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'OrderItems' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "productId" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "productId" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "productId" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "quantity" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" DROP CONSTRAINT "OrderItems_OrderId_fkey"
Executing (default): ALTER TABLE "OrderItems"  ADD FOREIGN KEY ("OrderId") REFERENCES "Orders" ("id") ON DELETE SET NULL ON UPDATE CASCADE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'OrderItems' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'ProcessedEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'ProcessedEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'ProcessedEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'ProcessedEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'DeadLetterEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'DeadLetterEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'DeadLetterEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" TYPE JSON;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" TYPE TEXT;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'DeadLetterEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
{"level":"ERROR","timestamp":"2026-02-25T10:42:12.560Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:42:12.561Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":263}
{"level":"ERROR","timestamp":"2026-02-25T10:42:12.840Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:42:12.841Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":546}
{"level":"ERROR","timestamp":"2026-02-25T10:42:13.399Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:42:13.400Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":1034}
{"level":"ERROR","timestamp":"2026-02-25T10:42:14.443Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:42:14.444Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":1912}
{"level":"ERROR","timestamp":"2026-02-25T10:42:16.363Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:42:16.363Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":4262}
{"level":"ERROR","timestamp":"2026-02-25T10:42:20.637Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:42:20.638Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":9880}
{"error":"Connection error: getaddrinfo ENOTFOUND kafka","level":"error","message":"Failed to connect Kafka producer on startup","timestamp":"2026-02-25T10:42:20.640Z"}
Server is running on port 3001
{"level":"ERROR","timestamp":"2026-02-25T10:42:20.652Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:42:20.653Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":352}
{"level":"ERROR","timestamp":"2026-02-25T10:42:21.018Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:42:21.018Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":688}
{"level":"ERROR","timestamp":"2026-02-25T10:42:21.719Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:42:21.720Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":1448}
{"level":"ERROR","timestamp":"2026-02-25T10:42:23.183Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:42:23.184Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":3394}
{"level":"info","message":"::ffff:172.18.0.2 - - [25/Feb/2026:10:42:23 +0000] \"GET /metrics HTTP/1.1\" 200 - \"-\" \"Prometheus/3.7.1\"","timestamp":"2026-02-25T10:42:23.547Z"}
{"level":"ERROR","timestamp":"2026-02-25T10:42:26.593Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:42:26.595Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":6958}
{"level":"ERROR","timestamp":"2026-02-25T10:42:33.569Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:42:33.570Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":15818}
node:internal/process/promises:288
            triggerUncaughtException(err, true /* fromPromise */);
            ^

KafkaJSNonRetriableError
  Caused by: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
    at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
    ... 3 lines matching cause stack trace ...
    at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
  name: 'KafkaJSNumberOfRetriesExceeded',
  retriable: false,
  helpUrl: undefined,
  retryCount: 5,
  retryTime: 15818,
  [cause]: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
      at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
      at Socket.emit (node:events:517:28)
      at emitErrorNT (node:internal/streams/destroy:151:8)
      at emitErrorCloseNT (node:internal/streams/destroy:116:3)
      at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
    retriable: true,
    helpUrl: undefined,
    broker: 'kafka:9092',
    code: 'ENOTFOUND',
    [cause]: undefined
  }
}

Node.js v18.20.8

> order-service@1.0.0 start
> node index.js

[dotenv@17.3.1] injecting env (0) from .env -- tip: âš™ï¸  load multiple .env files with { path: ['.env.local', '.env'] }
{"level":"WARN","timestamp":"2026-02-25T10:42:34.433Z","logger":"kafkajs","message":"KafkaJS v2.0.0 switched default partitioner. To retain the same partitioning behavior as in previous versions, create the producer with the option \"createPartitioner: Partitioners.LegacyPartitioner\". See the migration guide at https://kafka.js.org/docs/migration-guide-v2.0.0#producer-new-default-partitioner for details. Silence this warning by setting the environment variable \"KAFKAJS_NO_PARTITIONER_WARNING=1\""}
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'Orders'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'Orders' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'Orders' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "userId" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "userId" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "userId" TYPE INTEGER;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "status" DROP NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "status" SET DEFAULT 'Pending';ALTER TABLE "Orders" ALTER COLUMN "status" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'Orders' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'OrderItems'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'OrderItems' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'OrderItems' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "productId" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "productId" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "productId" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "quantity" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" DROP CONSTRAINT "OrderItems_OrderId_fkey"
Executing (default): ALTER TABLE "OrderItems"  ADD FOREIGN KEY ("OrderId") REFERENCES "Orders" ("id") ON DELETE SET NULL ON UPDATE CASCADE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'OrderItems' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'ProcessedEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'ProcessedEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'ProcessedEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'ProcessedEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'DeadLetterEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'DeadLetterEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'DeadLetterEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" TYPE JSON;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" TYPE TEXT;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'DeadLetterEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
{"level":"ERROR","timestamp":"2026-02-25T10:42:34.526Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:42:34.527Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":306}
{"level":"ERROR","timestamp":"2026-02-25T10:42:34.841Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:42:34.842Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":664}
{"level":"ERROR","timestamp":"2026-02-25T10:42:35.519Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:42:35.520Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":1218}
{"level":"ERROR","timestamp":"2026-02-25T10:42:36.751Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:42:36.753Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":2132}
{"level":"ERROR","timestamp":"2026-02-25T10:42:38.894Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:42:38.894Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":4356}
{"level":"ERROR","timestamp":"2026-02-25T10:42:43.262Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:42:43.264Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":9844}
{"error":"Connection error: getaddrinfo ENOTFOUND kafka","level":"error","message":"Failed to connect Kafka producer on startup","timestamp":"2026-02-25T10:42:43.266Z"}
Server is running on port 3001
{"level":"ERROR","timestamp":"2026-02-25T10:42:43.279Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:42:43.279Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":244}
{"level":"ERROR","timestamp":"2026-02-25T10:42:43.539Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:42:43.541Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":450}
{"level":"ERROR","timestamp":"2026-02-25T10:42:44.005Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:42:44.006Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":946}
{"level":"ERROR","timestamp":"2026-02-25T10:42:44.960Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:42:44.961Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":2124}
{"level":"ERROR","timestamp":"2026-02-25T10:42:47.097Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:42:47.098Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":4730}
{"level":"ERROR","timestamp":"2026-02-25T10:42:51.839Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:42:51.841Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":10508}
node:internal/process/promises:288
            triggerUncaughtException(err, true /* fromPromise */);
            ^

KafkaJSNonRetriableError
  Caused by: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
    at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
    ... 3 lines matching cause stack trace ...
    at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
  name: 'KafkaJSNumberOfRetriesExceeded',
  retriable: false,
  helpUrl: undefined,
  retryCount: 5,
  retryTime: 10508,
  [cause]: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
      at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
      at Socket.emit (node:events:517:28)
      at emitErrorNT (node:internal/streams/destroy:151:8)
      at emitErrorCloseNT (node:internal/streams/destroy:116:3)
      at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
    retriable: true,
    helpUrl: undefined,
    broker: 'kafka:9092',
    code: 'ENOTFOUND',
    [cause]: undefined
  }
}

Node.js v18.20.8

> order-service@1.0.0 start
> node index.js

[dotenv@17.3.1] injecting env (0) from .env -- tip: âš™ï¸  suppress all logs with { quiet: true }
{"level":"WARN","timestamp":"2026-02-25T10:42:52.564Z","logger":"kafkajs","message":"KafkaJS v2.0.0 switched default partitioner. To retain the same partitioning behavior as in previous versions, create the producer with the option \"createPartitioner: Partitioners.LegacyPartitioner\". See the migration guide at https://kafka.js.org/docs/migration-guide-v2.0.0#producer-new-default-partitioner for details. Silence this warning by setting the environment variable \"KAFKAJS_NO_PARTITIONER_WARNING=1\""}
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'Orders'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'Orders' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'Orders' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "userId" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "userId" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "userId" TYPE INTEGER;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "status" DROP NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "status" SET DEFAULT 'Pending';ALTER TABLE "Orders" ALTER COLUMN "status" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'Orders' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'OrderItems'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'OrderItems' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'OrderItems' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "productId" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "productId" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "productId" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "quantity" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" DROP CONSTRAINT "OrderItems_OrderId_fkey"
Executing (default): ALTER TABLE "OrderItems"  ADD FOREIGN KEY ("OrderId") REFERENCES "Orders" ("id") ON DELETE SET NULL ON UPDATE CASCADE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'OrderItems' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'ProcessedEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'ProcessedEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'ProcessedEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'ProcessedEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'DeadLetterEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'DeadLetterEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'DeadLetterEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" TYPE JSON;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" TYPE TEXT;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'DeadLetterEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
{"level":"ERROR","timestamp":"2026-02-25T10:42:52.646Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:42:52.647Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":310}
{"level":"ERROR","timestamp":"2026-02-25T10:42:52.968Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:42:52.970Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":722}
{"level":"ERROR","timestamp":"2026-02-25T10:42:53.703Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:42:53.703Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":1506}
{"level":"ERROR","timestamp":"2026-02-25T10:42:55.216Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:42:55.216Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":3480}
{"level":"ERROR","timestamp":"2026-02-25T10:42:58.709Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:42:58.710Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":7318}
{"level":"ERROR","timestamp":"2026-02-25T10:43:06.045Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:43:06.047Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":15468}
{"error":"Connection error: getaddrinfo ENOTFOUND kafka","level":"error","message":"Failed to connect Kafka producer on startup","timestamp":"2026-02-25T10:43:06.050Z"}
Server is running on port 3001
{"level":"ERROR","timestamp":"2026-02-25T10:43:06.065Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:43:06.066Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":246}
{"level":"ERROR","timestamp":"2026-02-25T10:43:06.320Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:43:06.321Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":400}
{"level":"ERROR","timestamp":"2026-02-25T10:43:06.731Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:43:06.731Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":912}
{"level":"ERROR","timestamp":"2026-02-25T10:43:07.651Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:43:07.651Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":2166}
{"level":"info","message":"::ffff:172.18.0.2 - - [25/Feb/2026:10:43:08 +0000] \"GET /metrics HTTP/1.1\" 200 - \"-\" \"Prometheus/3.7.1\"","timestamp":"2026-02-25T10:43:08.554Z"}
{"level":"ERROR","timestamp":"2026-02-25T10:43:09.827Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:43:09.828Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":5100}
{"level":"ERROR","timestamp":"2026-02-25T10:43:14.946Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:43:14.947Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":9932}
node:internal/process/promises:288
            triggerUncaughtException(err, true /* fromPromise */);
            ^

KafkaJSNonRetriableError
  Caused by: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
    at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
    ... 3 lines matching cause stack trace ...
    at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
  name: 'KafkaJSNumberOfRetriesExceeded',
  retriable: false,
  helpUrl: undefined,
  retryCount: 5,
  retryTime: 9932,
  [cause]: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
      at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
      at Socket.emit (node:events:517:28)
      at emitErrorNT (node:internal/streams/destroy:151:8)
      at emitErrorCloseNT (node:internal/streams/destroy:116:3)
      at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
    retriable: true,
    helpUrl: undefined,
    broker: 'kafka:9092',
    code: 'ENOTFOUND',
    [cause]: undefined
  }
}

Node.js v18.20.8

> order-service@1.0.0 start
> node index.js

[dotenv@17.3.1] injecting env (0) from .env -- tip: ðŸ› ï¸  run anywhere with `dotenvx run -- yourcommand`
{"level":"WARN","timestamp":"2026-02-25T10:43:15.673Z","logger":"kafkajs","message":"KafkaJS v2.0.0 switched default partitioner. To retain the same partitioning behavior as in previous versions, create the producer with the option \"createPartitioner: Partitioners.LegacyPartitioner\". See the migration guide at https://kafka.js.org/docs/migration-guide-v2.0.0#producer-new-default-partitioner for details. Silence this warning by setting the environment variable \"KAFKAJS_NO_PARTITIONER_WARNING=1\""}
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'Orders'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'Orders' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'Orders' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "userId" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "userId" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "userId" TYPE INTEGER;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "status" DROP NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "status" SET DEFAULT 'Pending';ALTER TABLE "Orders" ALTER COLUMN "status" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'Orders' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'OrderItems'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'OrderItems' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'OrderItems' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "productId" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "productId" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "productId" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "quantity" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" DROP CONSTRAINT "OrderItems_OrderId_fkey"
Executing (default): ALTER TABLE "OrderItems"  ADD FOREIGN KEY ("OrderId") REFERENCES "Orders" ("id") ON DELETE SET NULL ON UPDATE CASCADE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'OrderItems' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'ProcessedEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'ProcessedEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'ProcessedEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'ProcessedEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'DeadLetterEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'DeadLetterEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'DeadLetterEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" TYPE JSON;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" TYPE TEXT;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'DeadLetterEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
{"level":"ERROR","timestamp":"2026-02-25T10:43:15.773Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:43:15.774Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":274}
{"level":"ERROR","timestamp":"2026-02-25T10:43:16.059Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:43:16.060Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":534}
{"level":"ERROR","timestamp":"2026-02-25T10:43:16.603Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:43:16.604Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":920}
{"level":"ERROR","timestamp":"2026-02-25T10:43:18.284Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:43:18.321Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":2182}
{"level":"ERROR","timestamp":"2026-02-25T10:43:30.043Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:43:30.044Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":5178}
{"level":"ERROR","timestamp":"2026-02-25T10:43:35.255Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:43:35.263Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":10660}
{"error":"Connection error: getaddrinfo ENOTFOUND kafka","level":"error","message":"Failed to connect Kafka producer on startup","timestamp":"2026-02-25T10:43:35.282Z"}
Server is running on port 3001
{"level":"ERROR","timestamp":"2026-02-25T10:43:35.458Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:43:35.459Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":244}
{"level":"ERROR","timestamp":"2026-02-25T10:43:35.716Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:43:35.718Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":484}
{"level":"ERROR","timestamp":"2026-02-25T10:43:36.214Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:43:36.215Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":978}
{"level":"ERROR","timestamp":"2026-02-25T10:43:37.207Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:43:37.208Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":1726}
{"level":"ERROR","timestamp":"2026-02-25T10:43:38.946Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:43:38.948Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":3204}
{"level":"ERROR","timestamp":"2026-02-25T10:43:42.161Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:43:42.161Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":6314}
node:internal/process/promises:288
            triggerUncaughtException(err, true /* fromPromise */);
            ^

KafkaJSNonRetriableError
  Caused by: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
    at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
    ... 3 lines matching cause stack trace ...
    at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
  name: 'KafkaJSNumberOfRetriesExceeded',
  retriable: false,
  helpUrl: undefined,
  retryCount: 5,
  retryTime: 6314,
  [cause]: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
      at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
      at Socket.emit (node:events:517:28)
      at emitErrorNT (node:internal/streams/destroy:151:8)
      at emitErrorCloseNT (node:internal/streams/destroy:116:3)
      at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
    retriable: true,
    helpUrl: undefined,
    broker: 'kafka:9092',
    code: 'ENOTFOUND',
    [cause]: undefined
  }
}

Node.js v18.20.8

> order-service@1.0.0 start
> node index.js

[dotenv@17.3.1] injecting env (0) from .env -- tip: âš™ï¸  load multiple .env files with { path: ['.env.local', '.env'] }
{"level":"WARN","timestamp":"2026-02-25T10:43:42.793Z","logger":"kafkajs","message":"KafkaJS v2.0.0 switched default partitioner. To retain the same partitioning behavior as in previous versions, create the producer with the option \"createPartitioner: Partitioners.LegacyPartitioner\". See the migration guide at https://kafka.js.org/docs/migration-guide-v2.0.0#producer-new-default-partitioner for details. Silence this warning by setting the environment variable \"KAFKAJS_NO_PARTITIONER_WARNING=1\""}
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'Orders'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'Orders' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'Orders' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "userId" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "userId" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "userId" TYPE INTEGER;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "status" DROP NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "status" SET DEFAULT 'Pending';ALTER TABLE "Orders" ALTER COLUMN "status" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'Orders' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'OrderItems'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'OrderItems' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'OrderItems' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "productId" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "productId" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "productId" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "quantity" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" DROP CONSTRAINT "OrderItems_OrderId_fkey"
Executing (default): ALTER TABLE "OrderItems"  ADD FOREIGN KEY ("OrderId") REFERENCES "Orders" ("id") ON DELETE SET NULL ON UPDATE CASCADE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'OrderItems' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'ProcessedEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'ProcessedEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'ProcessedEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'ProcessedEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'DeadLetterEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'DeadLetterEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'DeadLetterEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" TYPE JSON;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" TYPE TEXT;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'DeadLetterEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
{"level":"ERROR","timestamp":"2026-02-25T10:43:42.906Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:43:42.908Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":359}
{"level":"ERROR","timestamp":"2026-02-25T10:43:43.279Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:43:43.280Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":584}
{"level":"ERROR","timestamp":"2026-02-25T10:43:43.877Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:43:43.877Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":1210}
{"level":"ERROR","timestamp":"2026-02-25T10:43:45.101Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:43:45.103Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":2340}
{"level":"ERROR","timestamp":"2026-02-25T10:43:47.453Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:43:47.454Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":4052}
{"level":"ERROR","timestamp":"2026-02-25T10:43:51.518Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:43:51.519Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":8026}
{"error":"Connection error: getaddrinfo ENOTFOUND kafka","level":"error","message":"Failed to connect Kafka producer on startup","timestamp":"2026-02-25T10:43:51.520Z"}
Server is running on port 3001
{"level":"ERROR","timestamp":"2026-02-25T10:43:51.535Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:43:51.537Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":327}
{"level":"ERROR","timestamp":"2026-02-25T10:43:51.873Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:43:51.874Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":678}
{"level":"ERROR","timestamp":"2026-02-25T10:43:52.565Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:43:52.566Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":1568}
{"level":"ERROR","timestamp":"2026-02-25T10:43:54.143Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:43:54.143Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":2710}
{"level":"ERROR","timestamp":"2026-02-25T10:43:56.862Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:43:56.863Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":4658}
{"level":"ERROR","timestamp":"2026-02-25T10:44:01.526Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:44:01.527Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":7506}
node:internal/process/promises:288
            triggerUncaughtException(err, true /* fromPromise */);
            ^

KafkaJSNonRetriableError
  Caused by: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
    at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
    ... 3 lines matching cause stack trace ...
    at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
  name: 'KafkaJSNumberOfRetriesExceeded',
  retriable: false,
  helpUrl: undefined,
  retryCount: 5,
  retryTime: 7506,
  [cause]: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
      at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
      at Socket.emit (node:events:517:28)
      at emitErrorNT (node:internal/streams/destroy:151:8)
      at emitErrorCloseNT (node:internal/streams/destroy:116:3)
      at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
    retriable: true,
    helpUrl: undefined,
    broker: 'kafka:9092',
    code: 'ENOTFOUND',
    [cause]: undefined
  }
}

Node.js v18.20.8

> order-service@1.0.0 start
> node index.js

[dotenv@17.3.1] injecting env (0) from .env -- tip: âš™ï¸  write to custom object with { processEnv: myObject }
{"level":"WARN","timestamp":"2026-02-25T10:44:02.246Z","logger":"kafkajs","message":"KafkaJS v2.0.0 switched default partitioner. To retain the same partitioning behavior as in previous versions, create the producer with the option \"createPartitioner: Partitioners.LegacyPartitioner\". See the migration guide at https://kafka.js.org/docs/migration-guide-v2.0.0#producer-new-default-partitioner for details. Silence this warning by setting the environment variable \"KAFKAJS_NO_PARTITIONER_WARNING=1\""}
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'Orders'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'Orders' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'Orders' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "userId" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "userId" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "userId" TYPE INTEGER;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "status" DROP NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "status" SET DEFAULT 'Pending';ALTER TABLE "Orders" ALTER COLUMN "status" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'Orders' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'OrderItems'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'OrderItems' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'OrderItems' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "productId" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "productId" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "productId" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "quantity" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" DROP CONSTRAINT "OrderItems_OrderId_fkey"
Executing (default): ALTER TABLE "OrderItems"  ADD FOREIGN KEY ("OrderId") REFERENCES "Orders" ("id") ON DELETE SET NULL ON UPDATE CASCADE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'OrderItems' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'ProcessedEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'ProcessedEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'ProcessedEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'ProcessedEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'DeadLetterEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'DeadLetterEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'DeadLetterEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" TYPE JSON;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" TYPE TEXT;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'DeadLetterEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
{"level":"ERROR","timestamp":"2026-02-25T10:44:02.333Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:44:02.334Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":310}
{"level":"ERROR","timestamp":"2026-02-25T10:44:02.659Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:44:02.661Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":638}
{"level":"ERROR","timestamp":"2026-02-25T10:44:03.312Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:44:03.313Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":1462}
{"level":"ERROR","timestamp":"2026-02-25T10:44:04.787Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:44:04.789Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":2618}
{"level":"ERROR","timestamp":"2026-02-25T10:44:07.423Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:44:07.424Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":5534}
{"level":"ERROR","timestamp":"2026-02-25T10:44:12.969Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:44:12.971Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":9644}
{"error":"Connection error: getaddrinfo ENOTFOUND kafka","level":"error","message":"Failed to connect Kafka producer on startup","timestamp":"2026-02-25T10:44:12.973Z"}
Server is running on port 3001
{"level":"ERROR","timestamp":"2026-02-25T10:44:12.988Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:44:12.989Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":351}
{"level":"ERROR","timestamp":"2026-02-25T10:44:13.353Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:44:13.354Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":618}
{"level":"ERROR","timestamp":"2026-02-25T10:44:13.982Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:44:13.983Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":1450}
{"level":"ERROR","timestamp":"2026-02-25T10:44:15.445Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:44:15.446Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":2484}
{"level":"ERROR","timestamp":"2026-02-25T10:44:17.938Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:44:17.939Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":5508}
{"level":"info","message":"::ffff:172.18.0.2 - - [25/Feb/2026:10:44:18 +0000] \"GET /metrics HTTP/1.1\" 200 - \"-\" \"Prometheus/3.7.1\"","timestamp":"2026-02-25T10:44:18.040Z"}
{"level":"ERROR","timestamp":"2026-02-25T10:44:23.462Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:44:23.463Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":11610}
node:internal/process/promises:288
            triggerUncaughtException(err, true /* fromPromise */);
            ^

KafkaJSNonRetriableError
  Caused by: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
    at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
    ... 3 lines matching cause stack trace ...
    at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
  name: 'KafkaJSNumberOfRetriesExceeded',
  retriable: false,
  helpUrl: undefined,
  retryCount: 5,
  retryTime: 11610,
  [cause]: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
      at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
      at Socket.emit (node:events:517:28)
      at emitErrorNT (node:internal/streams/destroy:151:8)
      at emitErrorCloseNT (node:internal/streams/destroy:116:3)
      at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
    retriable: true,
    helpUrl: undefined,
    broker: 'kafka:9092',
    code: 'ENOTFOUND',
    [cause]: undefined
  }
}

Node.js v18.20.8

> order-service@1.0.0 start
> node index.js

[dotenv@17.3.1] injecting env (0) from .env -- tip: âš™ï¸  write to custom object with { processEnv: myObject }
{"level":"WARN","timestamp":"2026-02-25T10:44:24.266Z","logger":"kafkajs","message":"KafkaJS v2.0.0 switched default partitioner. To retain the same partitioning behavior as in previous versions, create the producer with the option \"createPartitioner: Partitioners.LegacyPartitioner\". See the migration guide at https://kafka.js.org/docs/migration-guide-v2.0.0#producer-new-default-partitioner for details. Silence this warning by setting the environment variable \"KAFKAJS_NO_PARTITIONER_WARNING=1\""}
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'Orders'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'Orders' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'Orders' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "userId" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "userId" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "userId" TYPE INTEGER;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "status" DROP NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "status" SET DEFAULT 'Pending';ALTER TABLE "Orders" ALTER COLUMN "status" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'Orders' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'OrderItems'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'OrderItems' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'OrderItems' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "productId" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "productId" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "productId" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "quantity" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" DROP CONSTRAINT "OrderItems_OrderId_fkey"
Executing (default): ALTER TABLE "OrderItems"  ADD FOREIGN KEY ("OrderId") REFERENCES "Orders" ("id") ON DELETE SET NULL ON UPDATE CASCADE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'OrderItems' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'ProcessedEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'ProcessedEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'ProcessedEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'ProcessedEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'DeadLetterEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'DeadLetterEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'DeadLetterEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" TYPE JSON;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" TYPE TEXT;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'DeadLetterEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
{"level":"ERROR","timestamp":"2026-02-25T10:44:24.362Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:44:24.363Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":346}
{"level":"ERROR","timestamp":"2026-02-25T10:44:24.725Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:44:24.727Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":570}
{"level":"ERROR","timestamp":"2026-02-25T10:44:25.309Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:44:25.310Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":1140}
{"level":"ERROR","timestamp":"2026-02-25T10:44:26.463Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:44:26.467Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":2094}
{"level":"ERROR","timestamp":"2026-02-25T10:44:28.574Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:44:28.575Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":4024}
{"level":"ERROR","timestamp":"2026-02-25T10:44:32.617Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:44:32.619Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":8792}
{"error":"Connection error: getaddrinfo ENOTFOUND kafka","level":"error","message":"Failed to connect Kafka producer on startup","timestamp":"2026-02-25T10:44:32.621Z"}
Server is running on port 3001
{"level":"ERROR","timestamp":"2026-02-25T10:44:32.637Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:44:32.638Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":244}
{"level":"ERROR","timestamp":"2026-02-25T10:44:32.896Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:44:32.897Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":418}
{"level":"info","message":"::ffff:172.18.0.2 - - [25/Feb/2026:10:44:33 +0000] \"GET /metrics HTTP/1.1\" 200 - \"-\" \"Prometheus/3.7.1\"","timestamp":"2026-02-25T10:44:33.054Z"}
{"level":"ERROR","timestamp":"2026-02-25T10:44:33.329Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:44:33.330Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":930}
{"level":"ERROR","timestamp":"2026-02-25T10:44:34.272Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:44:34.273Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":1546}
{"level":"ERROR","timestamp":"2026-02-25T10:44:35.830Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:44:35.831Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":3184}
{"level":"ERROR","timestamp":"2026-02-25T10:44:39.026Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:44:39.027Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":5636}
node:internal/process/promises:288
            triggerUncaughtException(err, true /* fromPromise */);
            ^

KafkaJSNonRetriableError
  Caused by: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
    at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
    ... 3 lines matching cause stack trace ...
    at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
  name: 'KafkaJSNumberOfRetriesExceeded',
  retriable: false,
  helpUrl: undefined,
  retryCount: 5,
  retryTime: 5636,
  [cause]: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
      at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
      at Socket.emit (node:events:517:28)
      at emitErrorNT (node:internal/streams/destroy:151:8)
      at emitErrorCloseNT (node:internal/streams/destroy:116:3)
      at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
    retriable: true,
    helpUrl: undefined,
    broker: 'kafka:9092',
    code: 'ENOTFOUND',
    [cause]: undefined
  }
}

Node.js v18.20.8

> order-service@1.0.0 start
> node index.js

[dotenv@17.3.1] injecting env (0) from .env -- tip: âš™ï¸  load multiple .env files with { path: ['.env.local', '.env'] }
{"level":"WARN","timestamp":"2026-02-25T10:44:39.725Z","logger":"kafkajs","message":"KafkaJS v2.0.0 switched default partitioner. To retain the same partitioning behavior as in previous versions, create the producer with the option \"createPartitioner: Partitioners.LegacyPartitioner\". See the migration guide at https://kafka.js.org/docs/migration-guide-v2.0.0#producer-new-default-partitioner for details. Silence this warning by setting the environment variable \"KAFKAJS_NO_PARTITIONER_WARNING=1\""}
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'Orders'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'Orders' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'Orders' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "userId" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "userId" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "userId" TYPE INTEGER;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "status" DROP NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "status" SET DEFAULT 'Pending';ALTER TABLE "Orders" ALTER COLUMN "status" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'Orders' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'OrderItems'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'OrderItems' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'OrderItems' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "productId" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "productId" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "productId" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "quantity" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" DROP CONSTRAINT "OrderItems_OrderId_fkey"
Executing (default): ALTER TABLE "OrderItems"  ADD FOREIGN KEY ("OrderId") REFERENCES "Orders" ("id") ON DELETE SET NULL ON UPDATE CASCADE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'OrderItems' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'ProcessedEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'ProcessedEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'ProcessedEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'ProcessedEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'DeadLetterEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'DeadLetterEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'DeadLetterEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" TYPE JSON;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" TYPE TEXT;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'DeadLetterEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
{"level":"ERROR","timestamp":"2026-02-25T10:44:39.809Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:44:39.810Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":284}
{"level":"ERROR","timestamp":"2026-02-25T10:44:40.102Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:44:40.103Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":562}
{"level":"ERROR","timestamp":"2026-02-25T10:44:40.674Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:44:40.674Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":1166}
{"level":"ERROR","timestamp":"2026-02-25T10:44:41.847Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:44:41.848Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":2396}
{"level":"ERROR","timestamp":"2026-02-25T10:44:44.258Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:44:44.259Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":4084}
{"level":"ERROR","timestamp":"2026-02-25T10:44:48.355Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:44:48.358Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":7424}
{"error":"Connection error: getaddrinfo ENOTFOUND kafka","level":"error","message":"Failed to connect Kafka producer on startup","timestamp":"2026-02-25T10:44:48.360Z"}
Server is running on port 3001
{"level":"ERROR","timestamp":"2026-02-25T10:44:48.374Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:44:48.375Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":356}
{"level":"ERROR","timestamp":"2026-02-25T10:44:48.780Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:44:48.782Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":636}
{"level":"ERROR","timestamp":"2026-02-25T10:44:49.431Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:44:49.433Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":1428}
{"level":"ERROR","timestamp":"2026-02-25T10:44:50.870Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:44:50.870Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":2614}
{"level":"ERROR","timestamp":"2026-02-25T10:44:53.494Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:44:53.494Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":5106}
{"level":"ERROR","timestamp":"2026-02-25T10:44:58.612Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:44:58.613Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":9678}
node:internal/process/promises:288
            triggerUncaughtException(err, true /* fromPromise */);
            ^

KafkaJSNonRetriableError
  Caused by: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
    at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
    ... 3 lines matching cause stack trace ...
    at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
  name: 'KafkaJSNumberOfRetriesExceeded',
  retriable: false,
  helpUrl: undefined,
  retryCount: 5,
  retryTime: 9678,
  [cause]: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
      at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
      at Socket.emit (node:events:517:28)
      at emitErrorNT (node:internal/streams/destroy:151:8)
      at emitErrorCloseNT (node:internal/streams/destroy:116:3)
      at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
    retriable: true,
    helpUrl: undefined,
    broker: 'kafka:9092',
    code: 'ENOTFOUND',
    [cause]: undefined
  }
}

Node.js v18.20.8

> order-service@1.0.0 start
> node index.js

[dotenv@17.3.1] injecting env (0) from .env -- tip: âš™ï¸  specify custom .env file path with { path: '/custom/path/.env' }
{"level":"WARN","timestamp":"2026-02-25T10:44:59.296Z","logger":"kafkajs","message":"KafkaJS v2.0.0 switched default partitioner. To retain the same partitioning behavior as in previous versions, create the producer with the option \"createPartitioner: Partitioners.LegacyPartitioner\". See the migration guide at https://kafka.js.org/docs/migration-guide-v2.0.0#producer-new-default-partitioner for details. Silence this warning by setting the environment variable \"KAFKAJS_NO_PARTITIONER_WARNING=1\""}
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'Orders'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'Orders' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'Orders' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "userId" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "userId" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "userId" TYPE INTEGER;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "status" DROP NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "status" SET DEFAULT 'Pending';ALTER TABLE "Orders" ALTER COLUMN "status" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'Orders' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'OrderItems'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'OrderItems' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'OrderItems' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "productId" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "productId" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "productId" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "quantity" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" DROP CONSTRAINT "OrderItems_OrderId_fkey"
Executing (default): ALTER TABLE "OrderItems"  ADD FOREIGN KEY ("OrderId") REFERENCES "Orders" ("id") ON DELETE SET NULL ON UPDATE CASCADE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'OrderItems' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'ProcessedEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'ProcessedEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'ProcessedEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'ProcessedEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'DeadLetterEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'DeadLetterEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'DeadLetterEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" TYPE JSON;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" TYPE TEXT;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'DeadLetterEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
{"level":"ERROR","timestamp":"2026-02-25T10:44:59.381Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:44:59.381Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":284}
{"level":"ERROR","timestamp":"2026-02-25T10:44:59.679Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:44:59.680Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":500}
{"level":"ERROR","timestamp":"2026-02-25T10:45:00.192Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:45:00.192Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":1026}
{"level":"ERROR","timestamp":"2026-02-25T10:45:01.229Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:45:01.231Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":1710}
{"level":"ERROR","timestamp":"2026-02-25T10:45:02.949Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:45:02.950Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":3898}
{"level":"ERROR","timestamp":"2026-02-25T10:45:06.866Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:45:06.868Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":8756}
{"error":"Connection error: getaddrinfo ENOTFOUND kafka","level":"error","message":"Failed to connect Kafka producer on startup","timestamp":"2026-02-25T10:45:06.870Z"}
Server is running on port 3001
{"level":"ERROR","timestamp":"2026-02-25T10:45:06.887Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:45:06.888Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":278}
{"level":"ERROR","timestamp":"2026-02-25T10:45:07.174Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:45:07.174Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":502}
{"level":"ERROR","timestamp":"2026-02-25T10:45:07.689Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:45:07.690Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":1064}
{"level":"ERROR","timestamp":"2026-02-25T10:45:08.767Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:45:08.767Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":2022}
{"level":"ERROR","timestamp":"2026-02-25T10:45:10.796Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:45:10.797Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":4792}
{"level":"ERROR","timestamp":"2026-02-25T10:45:15.602Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:45:15.603Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":10922}
node:internal/process/promises:288
            triggerUncaughtException(err, true /* fromPromise */);
            ^

KafkaJSNonRetriableError
  Caused by: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
    at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
    ... 3 lines matching cause stack trace ...
    at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
  name: 'KafkaJSNumberOfRetriesExceeded',
  retriable: false,
  helpUrl: undefined,
  retryCount: 5,
  retryTime: 10922,
  [cause]: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
      at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
      at Socket.emit (node:events:517:28)
      at emitErrorNT (node:internal/streams/destroy:151:8)
      at emitErrorCloseNT (node:internal/streams/destroy:116:3)
      at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
    retriable: true,
    helpUrl: undefined,
    broker: 'kafka:9092',
    code: 'ENOTFOUND',
    [cause]: undefined
  }
}

Node.js v18.20.8

> order-service@1.0.0 start
> node index.js

[dotenv@17.3.1] injecting env (0) from .env -- tip: âš™ï¸  enable debug logging with { debug: true }
{"level":"WARN","timestamp":"2026-02-25T10:45:16.233Z","logger":"kafkajs","message":"KafkaJS v2.0.0 switched default partitioner. To retain the same partitioning behavior as in previous versions, create the producer with the option \"createPartitioner: Partitioners.LegacyPartitioner\". See the migration guide at https://kafka.js.org/docs/migration-guide-v2.0.0#producer-new-default-partitioner for details. Silence this warning by setting the environment variable \"KAFKAJS_NO_PARTITIONER_WARNING=1\""}
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'Orders'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'Orders' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'Orders' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "userId" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "userId" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "userId" TYPE INTEGER;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "status" DROP NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "status" SET DEFAULT 'Pending';ALTER TABLE "Orders" ALTER COLUMN "status" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'Orders' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'OrderItems'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'OrderItems' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'OrderItems' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "productId" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "productId" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "productId" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "quantity" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" DROP CONSTRAINT "OrderItems_OrderId_fkey"
Executing (default): ALTER TABLE "OrderItems"  ADD FOREIGN KEY ("OrderId") REFERENCES "Orders" ("id") ON DELETE SET NULL ON UPDATE CASCADE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'OrderItems' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'ProcessedEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'ProcessedEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'ProcessedEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'ProcessedEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'DeadLetterEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'DeadLetterEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'DeadLetterEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" TYPE JSON;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" TYPE TEXT;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'DeadLetterEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
{"level":"ERROR","timestamp":"2026-02-25T10:45:16.318Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:45:16.318Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":269}
{"level":"ERROR","timestamp":"2026-02-25T10:45:16.607Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:45:16.611Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":508}
{"level":"ERROR","timestamp":"2026-02-25T10:45:17.130Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:45:17.131Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":916}
{"level":"ERROR","timestamp":"2026-02-25T10:45:18.054Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:45:18.055Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":1762}
{"level":"ERROR","timestamp":"2026-02-25T10:45:19.826Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:45:19.827Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":3546}
{"level":"ERROR","timestamp":"2026-02-25T10:45:23.381Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:45:23.382Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":7630}
{"error":"Connection error: getaddrinfo ENOTFOUND kafka","level":"error","message":"Failed to connect Kafka producer on startup","timestamp":"2026-02-25T10:45:23.383Z"}
Server is running on port 3001
{"level":"ERROR","timestamp":"2026-02-25T10:45:23.393Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:45:23.393Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":345}
{"level":"ERROR","timestamp":"2026-02-25T10:45:23.746Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:45:23.746Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":710}
{"level":"ERROR","timestamp":"2026-02-25T10:45:24.465Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:45:24.466Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":1164}
{"level":"ERROR","timestamp":"2026-02-25T10:45:25.643Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:45:25.644Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":2300}
{"level":"ERROR","timestamp":"2026-02-25T10:45:27.956Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:45:27.957Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":4410}
{"level":"ERROR","timestamp":"2026-02-25T10:45:32.382Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:45:32.383Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":8880}
node:internal/process/promises:288
            triggerUncaughtException(err, true /* fromPromise */);
            ^

KafkaJSNonRetriableError
  Caused by: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
    at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
    ... 3 lines matching cause stack trace ...
    at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
  name: 'KafkaJSNumberOfRetriesExceeded',
  retriable: false,
  helpUrl: undefined,
  retryCount: 5,
  retryTime: 8880,
  [cause]: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
      at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
      at Socket.emit (node:events:517:28)
      at emitErrorNT (node:internal/streams/destroy:151:8)
      at emitErrorCloseNT (node:internal/streams/destroy:116:3)
      at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
    retriable: true,
    helpUrl: undefined,
    broker: 'kafka:9092',
    code: 'ENOTFOUND',
    [cause]: undefined
  }
}

Node.js v18.20.8

> order-service@1.0.0 start
> node index.js

[dotenv@17.3.1] injecting env (0) from .env -- tip: ðŸ” prevent building .env in docker: https://dotenvx.com/prebuild
{"level":"WARN","timestamp":"2026-02-25T10:45:33.147Z","logger":"kafkajs","message":"KafkaJS v2.0.0 switched default partitioner. To retain the same partitioning behavior as in previous versions, create the producer with the option \"createPartitioner: Partitioners.LegacyPartitioner\". See the migration guide at https://kafka.js.org/docs/migration-guide-v2.0.0#producer-new-default-partitioner for details. Silence this warning by setting the environment variable \"KAFKAJS_NO_PARTITIONER_WARNING=1\""}
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'Orders'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'Orders' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'Orders' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "userId" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "userId" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "userId" TYPE INTEGER;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "status" DROP NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "status" SET DEFAULT 'Pending';ALTER TABLE "Orders" ALTER COLUMN "status" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'Orders' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'OrderItems'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'OrderItems' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'OrderItems' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "productId" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "productId" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "productId" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "quantity" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" DROP CONSTRAINT "OrderItems_OrderId_fkey"
Executing (default): ALTER TABLE "OrderItems"  ADD FOREIGN KEY ("OrderId") REFERENCES "Orders" ("id") ON DELETE SET NULL ON UPDATE CASCADE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'OrderItems' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'ProcessedEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'ProcessedEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'ProcessedEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'ProcessedEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'DeadLetterEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'DeadLetterEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'DeadLetterEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" TYPE JSON;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" TYPE TEXT;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'DeadLetterEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
{"level":"ERROR","timestamp":"2026-02-25T10:45:33.243Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:45:33.244Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":324}
{"level":"ERROR","timestamp":"2026-02-25T10:45:33.581Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:45:33.583Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":724}
{"level":"ERROR","timestamp":"2026-02-25T10:45:34.320Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:45:34.320Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":1502}
{"level":"ERROR","timestamp":"2026-02-25T10:45:35.832Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:45:35.833Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":2430}
{"level":"ERROR","timestamp":"2026-02-25T10:45:38.273Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:45:38.273Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":5464}
{"level":"ERROR","timestamp":"2026-02-25T10:45:43.753Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:45:43.755Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":9838}
{"error":"Connection error: getaddrinfo ENOTFOUND kafka","level":"error","message":"Failed to connect Kafka producer on startup","timestamp":"2026-02-25T10:45:43.759Z"}
Server is running on port 3001
{"level":"ERROR","timestamp":"2026-02-25T10:45:43.773Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:45:43.774Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":268}
{"level":"ERROR","timestamp":"2026-02-25T10:45:44.055Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:45:44.056Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":566}
{"level":"ERROR","timestamp":"2026-02-25T10:45:44.636Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:45:44.637Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":1056}
{"level":"ERROR","timestamp":"2026-02-25T10:45:45.703Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:45:45.704Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":2418}
{"level":"info","message":"::ffff:172.18.0.2 - - [25/Feb/2026:10:45:48 +0000] \"GET /metrics HTTP/1.1\" 200 - \"-\" \"Prometheus/3.7.1\"","timestamp":"2026-02-25T10:45:48.044Z"}
{"level":"ERROR","timestamp":"2026-02-25T10:45:48.128Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:45:48.129Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":4540}
{"level":"ERROR","timestamp":"2026-02-25T10:45:52.684Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:45:52.685Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":7784}
node:internal/process/promises:288
            triggerUncaughtException(err, true /* fromPromise */);
            ^

KafkaJSNonRetriableError
  Caused by: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
    at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
    ... 3 lines matching cause stack trace ...
    at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
  name: 'KafkaJSNumberOfRetriesExceeded',
  retriable: false,
  helpUrl: undefined,
  retryCount: 5,
  retryTime: 7784,
  [cause]: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
      at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
      at Socket.emit (node:events:517:28)
      at emitErrorNT (node:internal/streams/destroy:151:8)
      at emitErrorCloseNT (node:internal/streams/destroy:116:3)
      at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
    retriable: true,
    helpUrl: undefined,
    broker: 'kafka:9092',
    code: 'ENOTFOUND',
    [cause]: undefined
  }
}

Node.js v18.20.8

> order-service@1.0.0 start
> node index.js

[dotenv@17.3.1] injecting env (0) from .env -- tip: âš™ï¸  load multiple .env files with { path: ['.env.local', '.env'] }
{"level":"WARN","timestamp":"2026-02-25T10:45:53.580Z","logger":"kafkajs","message":"KafkaJS v2.0.0 switched default partitioner. To retain the same partitioning behavior as in previous versions, create the producer with the option \"createPartitioner: Partitioners.LegacyPartitioner\". See the migration guide at https://kafka.js.org/docs/migration-guide-v2.0.0#producer-new-default-partitioner for details. Silence this warning by setting the environment variable \"KAFKAJS_NO_PARTITIONER_WARNING=1\""}
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'Orders'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'Orders' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'Orders' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "userId" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "userId" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "userId" TYPE INTEGER;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "status" DROP NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "status" SET DEFAULT 'Pending';ALTER TABLE "Orders" ALTER COLUMN "status" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'Orders' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'OrderItems'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'OrderItems' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'OrderItems' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "productId" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "productId" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "productId" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "quantity" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" DROP CONSTRAINT "OrderItems_OrderId_fkey"
Executing (default): ALTER TABLE "OrderItems"  ADD FOREIGN KEY ("OrderId") REFERENCES "Orders" ("id") ON DELETE SET NULL ON UPDATE CASCADE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'OrderItems' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'ProcessedEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'ProcessedEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'ProcessedEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'ProcessedEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'DeadLetterEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'DeadLetterEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'DeadLetterEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" TYPE JSON;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" TYPE TEXT;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'DeadLetterEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
{"level":"ERROR","timestamp":"2026-02-25T10:45:53.692Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:45:53.693Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":312}
{"level":"ERROR","timestamp":"2026-02-25T10:45:54.015Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:45:54.017Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":744}
{"level":"ERROR","timestamp":"2026-02-25T10:45:54.773Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:45:54.774Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":1276}
{"level":"ERROR","timestamp":"2026-02-25T10:45:56.065Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:45:56.067Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":2720}
{"level":"ERROR","timestamp":"2026-02-25T10:45:58.800Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:45:58.801Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":6362}
{"level":"ERROR","timestamp":"2026-02-25T10:46:05.175Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:46:05.178Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":10344}
{"error":"Connection error: getaddrinfo ENOTFOUND kafka","level":"error","message":"Failed to connect Kafka producer on startup","timestamp":"2026-02-25T10:46:05.180Z"}
Server is running on port 3001
{"level":"ERROR","timestamp":"2026-02-25T10:46:05.195Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:46:05.196Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":356}
{"level":"ERROR","timestamp":"2026-02-25T10:46:05.561Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:46:05.562Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":630}
{"level":"ERROR","timestamp":"2026-02-25T10:46:06.203Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:46:06.205Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":1332}
{"level":"ERROR","timestamp":"2026-02-25T10:46:07.548Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:46:07.549Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":2288}
{"level":"ERROR","timestamp":"2026-02-25T10:46:09.860Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:46:09.861Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":5450}
{"level":"ERROR","timestamp":"2026-02-25T10:46:15.324Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:46:15.325Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":9142}
node:internal/process/promises:288
            triggerUncaughtException(err, true /* fromPromise */);
            ^

KafkaJSNonRetriableError
  Caused by: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
    at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
    ... 3 lines matching cause stack trace ...
    at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
  name: 'KafkaJSNumberOfRetriesExceeded',
  retriable: false,
  helpUrl: undefined,
  retryCount: 5,
  retryTime: 9142,
  [cause]: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
      at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
      at Socket.emit (node:events:517:28)
      at emitErrorNT (node:internal/streams/destroy:151:8)
      at emitErrorCloseNT (node:internal/streams/destroy:116:3)
      at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
    retriable: true,
    helpUrl: undefined,
    broker: 'kafka:9092',
    code: 'ENOTFOUND',
    [cause]: undefined
  }
}

Node.js v18.20.8

> order-service@1.0.0 start
> node index.js

[dotenv@17.3.1] injecting env (0) from .env -- tip: ðŸ› ï¸  run anywhere with `dotenvx run -- yourcommand`
{"level":"WARN","timestamp":"2026-02-25T10:46:16.039Z","logger":"kafkajs","message":"KafkaJS v2.0.0 switched default partitioner. To retain the same partitioning behavior as in previous versions, create the producer with the option \"createPartitioner: Partitioners.LegacyPartitioner\". See the migration guide at https://kafka.js.org/docs/migration-guide-v2.0.0#producer-new-default-partitioner for details. Silence this warning by setting the environment variable \"KAFKAJS_NO_PARTITIONER_WARNING=1\""}
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'Orders'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'Orders' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'Orders' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "userId" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "userId" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "userId" TYPE INTEGER;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "status" DROP NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "status" SET DEFAULT 'Pending';ALTER TABLE "Orders" ALTER COLUMN "status" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'Orders' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'OrderItems'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'OrderItems' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'OrderItems' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "productId" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "productId" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "productId" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "quantity" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" DROP CONSTRAINT "OrderItems_OrderId_fkey"
Executing (default): ALTER TABLE "OrderItems"  ADD FOREIGN KEY ("OrderId") REFERENCES "Orders" ("id") ON DELETE SET NULL ON UPDATE CASCADE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'OrderItems' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'ProcessedEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'ProcessedEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'ProcessedEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'ProcessedEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'DeadLetterEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'DeadLetterEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'DeadLetterEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" TYPE JSON;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" TYPE TEXT;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'DeadLetterEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
{"level":"ERROR","timestamp":"2026-02-25T10:46:16.127Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:46:16.128Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":327}
{"level":"ERROR","timestamp":"2026-02-25T10:46:16.469Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:46:16.471Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":756}
{"level":"ERROR","timestamp":"2026-02-25T10:46:17.237Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:46:17.238Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":1756}
{"level":"ERROR","timestamp":"2026-02-25T10:46:19.010Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:46:19.012Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":4056}
{"level":"ERROR","timestamp":"2026-02-25T10:46:23.083Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:46:23.084Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":8584}
{"level":"ERROR","timestamp":"2026-02-25T10:46:31.715Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:46:31.773Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":17720}
{"error":"Connection error: getaddrinfo ENOTFOUND kafka","level":"error","message":"Failed to connect Kafka producer on startup","timestamp":"2026-02-25T10:46:31.783Z"}
Server is running on port 3001
{"level":"ERROR","timestamp":"2026-02-25T10:46:31.871Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:46:31.877Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":313}
{"level":"ERROR","timestamp":"2026-02-25T10:46:32.205Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:46:32.206Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":508}
{"level":"ERROR","timestamp":"2026-02-25T10:46:32.731Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:46:32.733Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":966}
{"level":"info","message":"::ffff:172.18.0.2 - - [25/Feb/2026:10:46:33 +0000] \"GET /metrics HTTP/1.1\" 200 - \"-\" \"Prometheus/3.7.1\"","timestamp":"2026-02-25T10:46:33.062Z"}
{"level":"ERROR","timestamp":"2026-02-25T10:46:33.709Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:46:33.709Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":2176}
{"level":"ERROR","timestamp":"2026-02-25T10:46:35.903Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:46:35.905Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":3564}
{"level":"ERROR","timestamp":"2026-02-25T10:46:39.483Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:46:39.483Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":7214}
node:internal/process/promises:288
            triggerUncaughtException(err, true /* fromPromise */);
            ^

KafkaJSNonRetriableError
  Caused by: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
    at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
    ... 3 lines matching cause stack trace ...
    at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
  name: 'KafkaJSNumberOfRetriesExceeded',
  retriable: false,
  helpUrl: undefined,
  retryCount: 5,
  retryTime: 7214,
  [cause]: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
      at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
      at Socket.emit (node:events:517:28)
      at emitErrorNT (node:internal/streams/destroy:151:8)
      at emitErrorCloseNT (node:internal/streams/destroy:116:3)
      at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
    retriable: true,
    helpUrl: undefined,
    broker: 'kafka:9092',
    code: 'ENOTFOUND',
    [cause]: undefined
  }
}

Node.js v18.20.8

> order-service@1.0.0 start
> node index.js

[dotenv@17.3.1] injecting env (0) from .env -- tip: ðŸ” encrypt with Dotenvx: https://dotenvx.com
{"level":"WARN","timestamp":"2026-02-25T10:46:40.301Z","logger":"kafkajs","message":"KafkaJS v2.0.0 switched default partitioner. To retain the same partitioning behavior as in previous versions, create the producer with the option \"createPartitioner: Partitioners.LegacyPartitioner\". See the migration guide at https://kafka.js.org/docs/migration-guide-v2.0.0#producer-new-default-partitioner for details. Silence this warning by setting the environment variable \"KAFKAJS_NO_PARTITIONER_WARNING=1\""}
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'Orders'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'Orders' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'Orders' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "userId" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "userId" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "userId" TYPE INTEGER;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "status" DROP NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "status" SET DEFAULT 'Pending';ALTER TABLE "Orders" ALTER COLUMN "status" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'Orders' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'OrderItems'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'OrderItems' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'OrderItems' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "productId" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "productId" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "productId" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "quantity" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" DROP CONSTRAINT "OrderItems_OrderId_fkey"
Executing (default): ALTER TABLE "OrderItems"  ADD FOREIGN KEY ("OrderId") REFERENCES "Orders" ("id") ON DELETE SET NULL ON UPDATE CASCADE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'OrderItems' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'ProcessedEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'ProcessedEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'ProcessedEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'ProcessedEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'DeadLetterEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'DeadLetterEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'DeadLetterEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" TYPE JSON;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" TYPE TEXT;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'DeadLetterEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
{"level":"ERROR","timestamp":"2026-02-25T10:46:40.398Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:46:40.399Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":295}
{"level":"ERROR","timestamp":"2026-02-25T10:46:40.703Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:46:40.704Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":658}
{"level":"ERROR","timestamp":"2026-02-25T10:46:41.370Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:46:41.371Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":1288}
{"level":"ERROR","timestamp":"2026-02-25T10:46:42.671Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:46:42.672Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":2916}
{"level":"ERROR","timestamp":"2026-02-25T10:46:45.605Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:46:45.606Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":6830}
{"level":"ERROR","timestamp":"2026-02-25T10:46:52.451Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:46:52.454Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":10980}
{"error":"Connection error: getaddrinfo ENOTFOUND kafka","level":"error","message":"Failed to connect Kafka producer on startup","timestamp":"2026-02-25T10:46:52.456Z"}
Server is running on port 3001
{"level":"ERROR","timestamp":"2026-02-25T10:46:52.475Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:46:52.476Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":303}
{"level":"ERROR","timestamp":"2026-02-25T10:46:52.793Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:46:52.794Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":672}
{"level":"ERROR","timestamp":"2026-02-25T10:46:53.481Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:46:53.483Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":1412}
{"level":"ERROR","timestamp":"2026-02-25T10:46:54.910Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:46:54.912Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":2804}
{"level":"ERROR","timestamp":"2026-02-25T10:46:57.728Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:46:57.729Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":5396}
{"level":"info","message":"::ffff:172.18.0.2 - - [25/Feb/2026:10:47:03 +0000] \"GET /metrics HTTP/1.1\" 200 - \"-\" \"Prometheus/3.7.1\"","timestamp":"2026-02-25T10:47:03.062Z"}
{"level":"ERROR","timestamp":"2026-02-25T10:47:03.138Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:47:03.139Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":9326}
node:internal/process/promises:288
            triggerUncaughtException(err, true /* fromPromise */);
            ^

KafkaJSNonRetriableError
  Caused by: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
    at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
    ... 3 lines matching cause stack trace ...
    at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
  name: 'KafkaJSNumberOfRetriesExceeded',
  retriable: false,
  helpUrl: undefined,
  retryCount: 5,
  retryTime: 9326,
  [cause]: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
      at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
      at Socket.emit (node:events:517:28)
      at emitErrorNT (node:internal/streams/destroy:151:8)
      at emitErrorCloseNT (node:internal/streams/destroy:116:3)
      at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
    retriable: true,
    helpUrl: undefined,
    broker: 'kafka:9092',
    code: 'ENOTFOUND',
    [cause]: undefined
  }
}

Node.js v18.20.8

> order-service@1.0.0 start
> node index.js

[dotenv@17.3.1] injecting env (0) from .env -- tip: ðŸ›¡ï¸ auth for agents: https://vestauth.com
{"level":"WARN","timestamp":"2026-02-25T10:47:03.930Z","logger":"kafkajs","message":"KafkaJS v2.0.0 switched default partitioner. To retain the same partitioning behavior as in previous versions, create the producer with the option \"createPartitioner: Partitioners.LegacyPartitioner\". See the migration guide at https://kafka.js.org/docs/migration-guide-v2.0.0#producer-new-default-partitioner for details. Silence this warning by setting the environment variable \"KAFKAJS_NO_PARTITIONER_WARNING=1\""}
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'Orders'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'Orders' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'Orders' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "userId" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "userId" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "userId" TYPE INTEGER;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "status" DROP NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "status" SET DEFAULT 'Pending';ALTER TABLE "Orders" ALTER COLUMN "status" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'Orders' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'OrderItems'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'OrderItems' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'OrderItems' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "productId" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "productId" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "productId" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "quantity" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" DROP CONSTRAINT "OrderItems_OrderId_fkey"
Executing (default): ALTER TABLE "OrderItems"  ADD FOREIGN KEY ("OrderId") REFERENCES "Orders" ("id") ON DELETE SET NULL ON UPDATE CASCADE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'OrderItems' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'ProcessedEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'ProcessedEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'ProcessedEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'ProcessedEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'DeadLetterEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'DeadLetterEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'DeadLetterEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" TYPE JSON;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" TYPE TEXT;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'DeadLetterEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
{"level":"ERROR","timestamp":"2026-02-25T10:47:04.044Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:47:04.046Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":336}
{"level":"ERROR","timestamp":"2026-02-25T10:47:04.395Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:47:04.396Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":556}
{"level":"ERROR","timestamp":"2026-02-25T10:47:04.966Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:47:04.967Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":1034}
{"level":"ERROR","timestamp":"2026-02-25T10:47:06.012Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:47:06.015Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":2250}
{"level":"ERROR","timestamp":"2026-02-25T10:47:08.273Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:47:08.274Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":3650}
{"level":"ERROR","timestamp":"2026-02-25T10:47:11.936Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:47:11.936Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":7776}
{"error":"Connection error: getaddrinfo ENOTFOUND kafka","level":"error","message":"Failed to connect Kafka producer on startup","timestamp":"2026-02-25T10:47:11.939Z"}
Server is running on port 3001
{"level":"ERROR","timestamp":"2026-02-25T10:47:11.953Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:47:11.954Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":313}
{"level":"ERROR","timestamp":"2026-02-25T10:47:12.277Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:47:12.279Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":522}
{"level":"ERROR","timestamp":"2026-02-25T10:47:12.814Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:47:12.816Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":992}
{"level":"ERROR","timestamp":"2026-02-25T10:47:13.821Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:47:13.822Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":2044}
{"level":"ERROR","timestamp":"2026-02-25T10:47:15.878Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:47:15.879Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":4642}
{"level":"info","message":"::ffff:172.18.0.2 - - [25/Feb/2026:10:47:18 +0000] \"GET /metrics HTTP/1.1\" 200 - \"-\" \"Prometheus/3.7.1\"","timestamp":"2026-02-25T10:47:18.046Z"}
{"level":"ERROR","timestamp":"2026-02-25T10:47:20.540Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:47:20.541Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":7932}
node:internal/process/promises:288
            triggerUncaughtException(err, true /* fromPromise */);
            ^

KafkaJSNonRetriableError
  Caused by: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
    at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
    ... 3 lines matching cause stack trace ...
    at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
  name: 'KafkaJSNumberOfRetriesExceeded',
  retriable: false,
  helpUrl: undefined,
  retryCount: 5,
  retryTime: 7932,
  [cause]: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
      at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
      at Socket.emit (node:events:517:28)
      at emitErrorNT (node:internal/streams/destroy:151:8)
      at emitErrorCloseNT (node:internal/streams/destroy:116:3)
      at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
    retriable: true,
    helpUrl: undefined,
    broker: 'kafka:9092',
    code: 'ENOTFOUND',
    [cause]: undefined
  }
}

Node.js v18.20.8

> order-service@1.0.0 start
> node index.js

[dotenv@17.3.1] injecting env (0) from .env -- tip: ðŸ” prevent building .env in docker: https://dotenvx.com/prebuild
{"level":"WARN","timestamp":"2026-02-25T10:47:21.321Z","logger":"kafkajs","message":"KafkaJS v2.0.0 switched default partitioner. To retain the same partitioning behavior as in previous versions, create the producer with the option \"createPartitioner: Partitioners.LegacyPartitioner\". See the migration guide at https://kafka.js.org/docs/migration-guide-v2.0.0#producer-new-default-partitioner for details. Silence this warning by setting the environment variable \"KAFKAJS_NO_PARTITIONER_WARNING=1\""}
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'Orders'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'Orders' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'Orders' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "userId" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "userId" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "userId" TYPE INTEGER;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "status" DROP NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "status" SET DEFAULT 'Pending';ALTER TABLE "Orders" ALTER COLUMN "status" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'Orders' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'OrderItems'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'OrderItems' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'OrderItems' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "productId" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "productId" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "productId" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "quantity" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" DROP CONSTRAINT "OrderItems_OrderId_fkey"
Executing (default): ALTER TABLE "OrderItems"  ADD FOREIGN KEY ("OrderId") REFERENCES "Orders" ("id") ON DELETE SET NULL ON UPDATE CASCADE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'OrderItems' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'ProcessedEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'ProcessedEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'ProcessedEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'ProcessedEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'DeadLetterEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'DeadLetterEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'DeadLetterEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" TYPE JSON;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" TYPE TEXT;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'DeadLetterEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
{"level":"ERROR","timestamp":"2026-02-25T10:47:21.451Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:47:21.453Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":336}
{"level":"ERROR","timestamp":"2026-02-25T10:47:21.807Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:47:21.809Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":624}
{"level":"ERROR","timestamp":"2026-02-25T10:47:22.445Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:47:22.446Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":1014}
{"level":"ERROR","timestamp":"2026-02-25T10:47:23.472Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:47:23.474Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":2360}
{"level":"ERROR","timestamp":"2026-02-25T10:47:25.849Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:47:25.851Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":5494}
{"level":"ERROR","timestamp":"2026-02-25T10:47:31.363Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:47:31.365Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":9404}
{"error":"Connection error: getaddrinfo ENOTFOUND kafka","level":"error","message":"Failed to connect Kafka producer on startup","timestamp":"2026-02-25T10:47:31.367Z"}
Server is running on port 3001
{"level":"ERROR","timestamp":"2026-02-25T10:47:31.382Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:47:31.383Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":249}
{"level":"ERROR","timestamp":"2026-02-25T10:47:31.643Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:47:31.644Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":558}
{"level":"ERROR","timestamp":"2026-02-25T10:47:32.216Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:47:32.218Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":1336}
{"level":"info","message":"::ffff:172.18.0.2 - - [25/Feb/2026:10:47:33 +0000] \"GET /metrics HTTP/1.1\" 200 - \"-\" \"Prometheus/3.7.1\"","timestamp":"2026-02-25T10:47:33.047Z"}
{"level":"ERROR","timestamp":"2026-02-25T10:47:33.567Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:47:33.568Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":2518}
{"level":"ERROR","timestamp":"2026-02-25T10:47:36.101Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:47:36.103Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":4652}
{"level":"ERROR","timestamp":"2026-02-25T10:47:40.765Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:47:40.765Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":10098}
node:internal/process/promises:288
            triggerUncaughtException(err, true /* fromPromise */);
            ^

KafkaJSNonRetriableError
  Caused by: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
    at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
    ... 3 lines matching cause stack trace ...
    at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
  name: 'KafkaJSNumberOfRetriesExceeded',
  retriable: false,
  helpUrl: undefined,
  retryCount: 5,
  retryTime: 10098,
  [cause]: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
      at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
      at Socket.emit (node:events:517:28)
      at emitErrorNT (node:internal/streams/destroy:151:8)
      at emitErrorCloseNT (node:internal/streams/destroy:116:3)
      at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
    retriable: true,
    helpUrl: undefined,
    broker: 'kafka:9092',
    code: 'ENOTFOUND',
    [cause]: undefined
  }
}

Node.js v18.20.8

> order-service@1.0.0 start
> node index.js

[dotenv@17.3.1] injecting env (0) from .env -- tip: ðŸ¤– agentic secret storage: https://dotenvx.com/as2
{"level":"WARN","timestamp":"2026-02-25T10:47:41.737Z","logger":"kafkajs","message":"KafkaJS v2.0.0 switched default partitioner. To retain the same partitioning behavior as in previous versions, create the producer with the option \"createPartitioner: Partitioners.LegacyPartitioner\". See the migration guide at https://kafka.js.org/docs/migration-guide-v2.0.0#producer-new-default-partitioner for details. Silence this warning by setting the environment variable \"KAFKAJS_NO_PARTITIONER_WARNING=1\""}
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'Orders'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'Orders' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'Orders' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "userId" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "userId" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "userId" TYPE INTEGER;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "status" DROP NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "status" SET DEFAULT 'Pending';ALTER TABLE "Orders" ALTER COLUMN "status" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'Orders' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'OrderItems'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'OrderItems' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'OrderItems' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "productId" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "productId" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "productId" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "quantity" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" DROP CONSTRAINT "OrderItems_OrderId_fkey"
Executing (default): ALTER TABLE "OrderItems"  ADD FOREIGN KEY ("OrderId") REFERENCES "Orders" ("id") ON DELETE SET NULL ON UPDATE CASCADE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'OrderItems' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'ProcessedEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'ProcessedEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'ProcessedEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'ProcessedEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'DeadLetterEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'DeadLetterEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'DeadLetterEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" TYPE JSON;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" TYPE TEXT;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'DeadLetterEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
{"level":"ERROR","timestamp":"2026-02-25T10:47:41.857Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:47:41.858Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":328}
{"level":"ERROR","timestamp":"2026-02-25T10:47:42.200Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:47:42.204Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":598}
{"level":"ERROR","timestamp":"2026-02-25T10:47:42.815Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:47:42.816Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":1358}
{"level":"ERROR","timestamp":"2026-02-25T10:47:44.182Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:47:44.183Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":2998}
{"level":"ERROR","timestamp":"2026-02-25T10:47:47.193Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:47:47.195Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":6208}
{"level":"ERROR","timestamp":"2026-02-25T10:47:53.417Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:47:53.419Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":12316}
{"error":"Connection error: getaddrinfo ENOTFOUND kafka","level":"error","message":"Failed to connect Kafka producer on startup","timestamp":"2026-02-25T10:47:53.421Z"}
Server is running on port 3001
{"level":"ERROR","timestamp":"2026-02-25T10:47:53.437Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:47:53.439Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":353}
{"level":"ERROR","timestamp":"2026-02-25T10:47:53.805Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:47:53.806Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":616}
{"level":"ERROR","timestamp":"2026-02-25T10:47:54.431Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:47:54.432Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":1356}
{"level":"ERROR","timestamp":"2026-02-25T10:47:55.799Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:47:55.800Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":3140}
{"level":"ERROR","timestamp":"2026-02-25T10:47:58.970Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:47:58.972Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":5482}
{"level":"info","message":"::ffff:172.18.0.2 - - [25/Feb/2026:10:48:03 +0000] \"GET /metrics HTTP/1.1\" 200 - \"-\" \"Prometheus/3.7.1\"","timestamp":"2026-02-25T10:48:03.087Z"}
{"level":"ERROR","timestamp":"2026-02-25T10:48:04.464Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:48:04.464Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":8890}
node:internal/process/promises:288
            triggerUncaughtException(err, true /* fromPromise */);
            ^

KafkaJSNonRetriableError
  Caused by: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
    at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
    ... 3 lines matching cause stack trace ...
    at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
  name: 'KafkaJSNumberOfRetriesExceeded',
  retriable: false,
  helpUrl: undefined,
  retryCount: 5,
  retryTime: 8890,
  [cause]: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
      at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
      at Socket.emit (node:events:517:28)
      at emitErrorNT (node:internal/streams/destroy:151:8)
      at emitErrorCloseNT (node:internal/streams/destroy:116:3)
      at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
    retriable: true,
    helpUrl: undefined,
    broker: 'kafka:9092',
    code: 'ENOTFOUND',
    [cause]: undefined
  }
}

Node.js v18.20.8

> order-service@1.0.0 start
> node index.js

[dotenv@17.3.1] injecting env (0) from .env -- tip: ðŸ¤– agentic secret storage: https://dotenvx.com/as2
{"level":"WARN","timestamp":"2026-02-25T10:48:05.784Z","logger":"kafkajs","message":"KafkaJS v2.0.0 switched default partitioner. To retain the same partitioning behavior as in previous versions, create the producer with the option \"createPartitioner: Partitioners.LegacyPartitioner\". See the migration guide at https://kafka.js.org/docs/migration-guide-v2.0.0#producer-new-default-partitioner for details. Silence this warning by setting the environment variable \"KAFKAJS_NO_PARTITIONER_WARNING=1\""}
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'Orders'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'Orders' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'Orders' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "userId" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "userId" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "userId" TYPE INTEGER;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "status" DROP NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "status" SET DEFAULT 'Pending';ALTER TABLE "Orders" ALTER COLUMN "status" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'Orders' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'OrderItems'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'OrderItems' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'OrderItems' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "productId" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "productId" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "productId" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "quantity" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" DROP CONSTRAINT "OrderItems_OrderId_fkey"
Executing (default): ALTER TABLE "OrderItems"  ADD FOREIGN KEY ("OrderId") REFERENCES "Orders" ("id") ON DELETE SET NULL ON UPDATE CASCADE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'OrderItems' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'ProcessedEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'ProcessedEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'ProcessedEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'ProcessedEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'DeadLetterEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'DeadLetterEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'DeadLetterEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" TYPE JSON;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" TYPE TEXT;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'DeadLetterEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
{"level":"ERROR","timestamp":"2026-02-25T10:48:05.980Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:48:05.981Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":259}
{"level":"ERROR","timestamp":"2026-02-25T10:48:06.252Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:48:06.253Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":518}
{"level":"ERROR","timestamp":"2026-02-25T10:48:06.786Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:48:06.787Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":988}
{"level":"ERROR","timestamp":"2026-02-25T10:48:07.785Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:48:07.788Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":2200}
{"level":"ERROR","timestamp":"2026-02-25T10:48:10.008Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:48:10.017Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":4340}
{"level":"ERROR","timestamp":"2026-02-25T10:48:14.374Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:48:14.377Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":10236}
{"error":"Connection error: getaddrinfo ENOTFOUND kafka","level":"error","message":"Failed to connect Kafka producer on startup","timestamp":"2026-02-25T10:48:14.383Z"}
Server is running on port 3001
{"level":"ERROR","timestamp":"2026-02-25T10:48:14.410Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:48:14.412Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":358}
{"level":"ERROR","timestamp":"2026-02-25T10:48:14.780Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:48:14.781Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":618}
{"level":"ERROR","timestamp":"2026-02-25T10:48:15.411Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:48:15.412Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":1304}
{"level":"ERROR","timestamp":"2026-02-25T10:48:16.729Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:48:16.730Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":3058}
{"level":"info","message":"::ffff:172.18.0.2 - - [25/Feb/2026:10:48:18 +0000] \"GET /metrics HTTP/1.1\" 200 - \"-\" \"Prometheus/3.7.1\"","timestamp":"2026-02-25T10:48:18.050Z"}
{"level":"ERROR","timestamp":"2026-02-25T10:48:19.811Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:48:19.813Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":7134}
{"level":"ERROR","timestamp":"2026-02-25T10:48:26.964Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:48:26.965Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":16782}
node:internal/process/promises:288
            triggerUncaughtException(err, true /* fromPromise */);
            ^

KafkaJSNonRetriableError
  Caused by: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
    at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
    ... 3 lines matching cause stack trace ...
    at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
  name: 'KafkaJSNumberOfRetriesExceeded',
  retriable: false,
  helpUrl: undefined,
  retryCount: 5,
  retryTime: 16782,
  [cause]: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
      at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
      at Socket.emit (node:events:517:28)
      at emitErrorNT (node:internal/streams/destroy:151:8)
      at emitErrorCloseNT (node:internal/streams/destroy:116:3)
      at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
    retriable: true,
    helpUrl: undefined,
    broker: 'kafka:9092',
    code: 'ENOTFOUND',
    [cause]: undefined
  }
}

Node.js v18.20.8

> order-service@1.0.0 start
> node index.js

[dotenv@17.3.1] injecting env (0) from .env -- tip: âš™ï¸  suppress all logs with { quiet: true }
{"level":"WARN","timestamp":"2026-02-25T10:48:27.871Z","logger":"kafkajs","message":"KafkaJS v2.0.0 switched default partitioner. To retain the same partitioning behavior as in previous versions, create the producer with the option \"createPartitioner: Partitioners.LegacyPartitioner\". See the migration guide at https://kafka.js.org/docs/migration-guide-v2.0.0#producer-new-default-partitioner for details. Silence this warning by setting the environment variable \"KAFKAJS_NO_PARTITIONER_WARNING=1\""}
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'Orders'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'Orders' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'Orders' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "userId" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "userId" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "userId" TYPE INTEGER;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "status" DROP NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "status" SET DEFAULT 'Pending';ALTER TABLE "Orders" ALTER COLUMN "status" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'Orders' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'OrderItems'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'OrderItems' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'OrderItems' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "productId" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "productId" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "productId" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "quantity" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" DROP CONSTRAINT "OrderItems_OrderId_fkey"
Executing (default): ALTER TABLE "OrderItems"  ADD FOREIGN KEY ("OrderId") REFERENCES "Orders" ("id") ON DELETE SET NULL ON UPDATE CASCADE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'OrderItems' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'ProcessedEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'ProcessedEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'ProcessedEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'ProcessedEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'DeadLetterEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'DeadLetterEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'DeadLetterEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" TYPE JSON;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" TYPE TEXT;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'DeadLetterEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
{"level":"ERROR","timestamp":"2026-02-25T10:48:28.018Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:48:28.019Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":356}
{"level":"ERROR","timestamp":"2026-02-25T10:48:28.385Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:48:28.387Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":720}
{"level":"ERROR","timestamp":"2026-02-25T10:48:29.119Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:48:29.120Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":1524}
{"level":"ERROR","timestamp":"2026-02-25T10:48:30.659Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:48:30.661Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":2850}
{"level":"ERROR","timestamp":"2026-02-25T10:48:33.529Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:48:33.530Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":4750}
{"level":"ERROR","timestamp":"2026-02-25T10:48:38.314Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:48:38.316Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":9514}
{"error":"Connection error: getaddrinfo ENOTFOUND kafka","level":"error","message":"Failed to connect Kafka producer on startup","timestamp":"2026-02-25T10:48:38.317Z"}
Server is running on port 3001
{"level":"ERROR","timestamp":"2026-02-25T10:48:38.329Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:48:38.330Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":297}
{"level":"ERROR","timestamp":"2026-02-25T10:48:38.646Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:48:38.647Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":712}
{"level":"ERROR","timestamp":"2026-02-25T10:48:39.373Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:48:39.375Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":1526}
{"level":"ERROR","timestamp":"2026-02-25T10:48:40.941Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:48:40.946Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":2870}
{"level":"ERROR","timestamp":"2026-02-25T10:48:43.851Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:48:43.854Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":6084}
{"level":"info","message":"::ffff:172.18.0.2 - - [25/Feb/2026:10:48:48 +0000] \"GET /metrics HTTP/1.1\" 200 - \"-\" \"Prometheus/3.7.1\"","timestamp":"2026-02-25T10:48:48.075Z"}
{"level":"ERROR","timestamp":"2026-02-25T10:48:49.996Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:48:49.998Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":14050}
node:internal/process/promises:288
            triggerUncaughtException(err, true /* fromPromise */);
            ^

KafkaJSNonRetriableError
  Caused by: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
    at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
    ... 3 lines matching cause stack trace ...
    at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
  name: 'KafkaJSNumberOfRetriesExceeded',
  retriable: false,
  helpUrl: undefined,
  retryCount: 5,
  retryTime: 14050,
  [cause]: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
      at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
      at Socket.emit (node:events:517:28)
      at emitErrorNT (node:internal/streams/destroy:151:8)
      at emitErrorCloseNT (node:internal/streams/destroy:116:3)
      at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
    retriable: true,
    helpUrl: undefined,
    broker: 'kafka:9092',
    code: 'ENOTFOUND',
    [cause]: undefined
  }
}

Node.js v18.20.8

> order-service@1.0.0 start
> node index.js

[dotenv@17.3.1] injecting env (0) from .env -- tip: âš™ï¸  suppress all logs with { quiet: true }
{"level":"WARN","timestamp":"2026-02-25T10:48:51.268Z","logger":"kafkajs","message":"KafkaJS v2.0.0 switched default partitioner. To retain the same partitioning behavior as in previous versions, create the producer with the option \"createPartitioner: Partitioners.LegacyPartitioner\". See the migration guide at https://kafka.js.org/docs/migration-guide-v2.0.0#producer-new-default-partitioner for details. Silence this warning by setting the environment variable \"KAFKAJS_NO_PARTITIONER_WARNING=1\""}
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'Orders'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'Orders' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'Orders' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "userId" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "userId" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "userId" TYPE INTEGER;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "status" DROP NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "status" SET DEFAULT 'Pending';ALTER TABLE "Orders" ALTER COLUMN "status" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'Orders' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'OrderItems'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'OrderItems' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'OrderItems' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "productId" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "productId" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "productId" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "quantity" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" DROP CONSTRAINT "OrderItems_OrderId_fkey"
Executing (default): ALTER TABLE "OrderItems"  ADD FOREIGN KEY ("OrderId") REFERENCES "Orders" ("id") ON DELETE SET NULL ON UPDATE CASCADE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'OrderItems' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'ProcessedEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'ProcessedEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'ProcessedEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'ProcessedEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'DeadLetterEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'DeadLetterEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'DeadLetterEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" TYPE JSON;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" TYPE TEXT;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'DeadLetterEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
{"level":"ERROR","timestamp":"2026-02-25T10:48:51.420Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:48:51.421Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":360}
{"level":"ERROR","timestamp":"2026-02-25T10:48:51.795Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:48:51.796Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":704}
{"level":"ERROR","timestamp":"2026-02-25T10:48:52.512Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:48:52.513Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":1582}
{"level":"ERROR","timestamp":"2026-02-25T10:48:54.112Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:48:54.115Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":3426}
{"level":"ERROR","timestamp":"2026-02-25T10:48:57.555Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:48:57.556Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":5602}
{"level":"ERROR","timestamp":"2026-02-25T10:49:03.175Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:49:03.179Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":11814}
{"error":"Connection error: getaddrinfo ENOTFOUND kafka","level":"error","message":"Failed to connect Kafka producer on startup","timestamp":"2026-02-25T10:49:03.182Z"}
Server is running on port 3001
{"level":"ERROR","timestamp":"2026-02-25T10:49:03.201Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:49:03.202Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":290}
{"level":"ERROR","timestamp":"2026-02-25T10:49:03.508Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:49:03.511Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":650}
{"level":"ERROR","timestamp":"2026-02-25T10:49:04.176Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:49:04.179Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":1558}
{"level":"ERROR","timestamp":"2026-02-25T10:49:05.746Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:49:05.747Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":2664}
{"level":"ERROR","timestamp":"2026-02-25T10:49:08.424Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:49:08.428Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":5038}
{"level":"ERROR","timestamp":"2026-02-25T10:49:13.486Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:49:13.487Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":11288}
node:internal/process/promises:288
            triggerUncaughtException(err, true /* fromPromise */);
            ^

KafkaJSNonRetriableError
  Caused by: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
    at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
    ... 3 lines matching cause stack trace ...
    at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
  name: 'KafkaJSNumberOfRetriesExceeded',
  retriable: false,
  helpUrl: undefined,
  retryCount: 5,
  retryTime: 11288,
  [cause]: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
      at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
      at Socket.emit (node:events:517:28)
      at emitErrorNT (node:internal/streams/destroy:151:8)
      at emitErrorCloseNT (node:internal/streams/destroy:116:3)
      at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
    retriable: true,
    helpUrl: undefined,
    broker: 'kafka:9092',
    code: 'ENOTFOUND',
    [cause]: undefined
  }
}

Node.js v18.20.8

> order-service@1.0.0 start
> node index.js

[dotenv@17.3.1] injecting env (0) from .env -- tip: ðŸ¤– agentic secret storage: https://dotenvx.com/as2
{"level":"WARN","timestamp":"2026-02-25T10:49:14.426Z","logger":"kafkajs","message":"KafkaJS v2.0.0 switched default partitioner. To retain the same partitioning behavior as in previous versions, create the producer with the option \"createPartitioner: Partitioners.LegacyPartitioner\". See the migration guide at https://kafka.js.org/docs/migration-guide-v2.0.0#producer-new-default-partitioner for details. Silence this warning by setting the environment variable \"KAFKAJS_NO_PARTITIONER_WARNING=1\""}
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'Orders'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'Orders' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'Orders' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "userId" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "userId" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "userId" TYPE INTEGER;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "status" DROP NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "status" SET DEFAULT 'Pending';ALTER TABLE "Orders" ALTER COLUMN "status" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'Orders' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'OrderItems'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'OrderItems' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'OrderItems' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "productId" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "productId" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "productId" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "quantity" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" DROP CONSTRAINT "OrderItems_OrderId_fkey"
Executing (default): ALTER TABLE "OrderItems"  ADD FOREIGN KEY ("OrderId") REFERENCES "Orders" ("id") ON DELETE SET NULL ON UPDATE CASCADE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'OrderItems' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'ProcessedEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'ProcessedEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'ProcessedEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'ProcessedEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'DeadLetterEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'DeadLetterEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'DeadLetterEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" TYPE JSON;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" TYPE TEXT;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'DeadLetterEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
{"level":"ERROR","timestamp":"2026-02-25T10:49:14.593Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:49:14.594Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":277}
{"level":"ERROR","timestamp":"2026-02-25T10:49:14.883Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:49:14.885Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":580}
{"level":"ERROR","timestamp":"2026-02-25T10:49:15.476Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:49:15.478Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":1342}
{"level":"ERROR","timestamp":"2026-02-25T10:49:16.838Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:49:16.841Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":3106}
{"level":"ERROR","timestamp":"2026-02-25T10:49:19.962Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:49:19.965Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":5140}
{"level":"ERROR","timestamp":"2026-02-25T10:49:25.117Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:49:25.119Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":9254}
{"error":"Connection error: getaddrinfo ENOTFOUND kafka","level":"error","message":"Failed to connect Kafka producer on startup","timestamp":"2026-02-25T10:49:25.122Z"}
Server is running on port 3001
{"level":"ERROR","timestamp":"2026-02-25T10:49:25.135Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:49:25.136Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":278}
{"level":"ERROR","timestamp":"2026-02-25T10:49:25.424Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:49:25.425Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":564}
{"level":"ERROR","timestamp":"2026-02-25T10:49:26.002Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:49:26.004Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":1074}
{"level":"ERROR","timestamp":"2026-02-25T10:49:27.091Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:49:27.092Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":2196}
{"level":"ERROR","timestamp":"2026-02-25T10:49:29.307Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:49:29.315Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":4636}
{"level":"info","message":"::ffff:172.18.0.2 - - [25/Feb/2026:10:49:33 +0000] \"GET /metrics HTTP/1.1\" 200 - \"-\" \"Prometheus/3.7.1\"","timestamp":"2026-02-25T10:49:33.058Z"}
{"level":"ERROR","timestamp":"2026-02-25T10:49:33.966Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:49:33.968Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":10554}
node:internal/process/promises:288
            triggerUncaughtException(err, true /* fromPromise */);
            ^

KafkaJSNonRetriableError
  Caused by: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
    at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
    ... 3 lines matching cause stack trace ...
    at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
  name: 'KafkaJSNumberOfRetriesExceeded',
  retriable: false,
  helpUrl: undefined,
  retryCount: 5,
  retryTime: 10554,
  [cause]: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
      at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
      at Socket.emit (node:events:517:28)
      at emitErrorNT (node:internal/streams/destroy:151:8)
      at emitErrorCloseNT (node:internal/streams/destroy:116:3)
      at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
    retriable: true,
    helpUrl: undefined,
    broker: 'kafka:9092',
    code: 'ENOTFOUND',
    [cause]: undefined
  }
}

Node.js v18.20.8

> order-service@1.0.0 start
> node index.js

[dotenv@17.3.1] injecting env (0) from .env -- tip: âš™ï¸  load multiple .env files with { path: ['.env.local', '.env'] }
{"level":"WARN","timestamp":"2026-02-25T10:49:35.166Z","logger":"kafkajs","message":"KafkaJS v2.0.0 switched default partitioner. To retain the same partitioning behavior as in previous versions, create the producer with the option \"createPartitioner: Partitioners.LegacyPartitioner\". See the migration guide at https://kafka.js.org/docs/migration-guide-v2.0.0#producer-new-default-partitioner for details. Silence this warning by setting the environment variable \"KAFKAJS_NO_PARTITIONER_WARNING=1\""}
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'Orders'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'Orders' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'Orders' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "userId" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "userId" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "userId" TYPE INTEGER;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "status" DROP NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "status" SET DEFAULT 'Pending';ALTER TABLE "Orders" ALTER COLUMN "status" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'Orders' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'OrderItems'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'OrderItems' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'OrderItems' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "productId" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "productId" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "productId" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "quantity" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" DROP CONSTRAINT "OrderItems_OrderId_fkey"
Executing (default): ALTER TABLE "OrderItems"  ADD FOREIGN KEY ("OrderId") REFERENCES "Orders" ("id") ON DELETE SET NULL ON UPDATE CASCADE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'OrderItems' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'ProcessedEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'ProcessedEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'ProcessedEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'ProcessedEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'DeadLetterEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'DeadLetterEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'DeadLetterEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" TYPE JSON;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" TYPE TEXT;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'DeadLetterEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
{"level":"ERROR","timestamp":"2026-02-25T10:49:35.690Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:49:35.692Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":334}
{"level":"ERROR","timestamp":"2026-02-25T10:49:36.045Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:49:36.047Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":748}
{"level":"ERROR","timestamp":"2026-02-25T10:49:36.811Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:49:36.821Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":1350}
{"level":"ERROR","timestamp":"2026-02-25T10:49:38.188Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:49:38.190Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":2182}
{"level":"ERROR","timestamp":"2026-02-25T10:49:40.387Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:49:40.388Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":5088}
{"level":"ERROR","timestamp":"2026-02-25T10:49:45.487Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:49:45.490Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":11662}
{"error":"Connection error: getaddrinfo ENOTFOUND kafka","level":"error","message":"Failed to connect Kafka producer on startup","timestamp":"2026-02-25T10:49:45.493Z"}
Server is running on port 3001
{"level":"ERROR","timestamp":"2026-02-25T10:49:45.531Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:49:45.538Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":320}
{"level":"ERROR","timestamp":"2026-02-25T10:49:45.869Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:49:45.870Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":668}
{"level":"ERROR","timestamp":"2026-02-25T10:49:46.548Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:49:46.548Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":1394}
{"level":"ERROR","timestamp":"2026-02-25T10:49:47.957Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:49:47.957Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":3202}
{"level":"info","message":"::ffff:172.18.0.2 - - [25/Feb/2026:10:49:48 +0000] \"GET /metrics HTTP/1.1\" 200 - \"-\" \"Prometheus/3.7.1\"","timestamp":"2026-02-25T10:49:48.060Z"}
{"level":"ERROR","timestamp":"2026-02-25T10:49:51.170Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:49:51.172Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":7214}
{"level":"ERROR","timestamp":"2026-02-25T10:49:58.405Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:49:58.407Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":14664}
node:internal/process/promises:288
            triggerUncaughtException(err, true /* fromPromise */);
            ^

KafkaJSNonRetriableError
  Caused by: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
    at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
    ... 3 lines matching cause stack trace ...
    at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
  name: 'KafkaJSNumberOfRetriesExceeded',
  retriable: false,
  helpUrl: undefined,
  retryCount: 5,
  retryTime: 14664,
  [cause]: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
      at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
      at Socket.emit (node:events:517:28)
      at emitErrorNT (node:internal/streams/destroy:151:8)
      at emitErrorCloseNT (node:internal/streams/destroy:116:3)
      at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
    retriable: true,
    helpUrl: undefined,
    broker: 'kafka:9092',
    code: 'ENOTFOUND',
    [cause]: undefined
  }
}

Node.js v18.20.8

> order-service@1.0.0 start
> node index.js

[dotenv@17.3.1] injecting env (0) from .env -- tip: ðŸ” encrypt with Dotenvx: https://dotenvx.com
{"level":"WARN","timestamp":"2026-02-25T10:49:59.260Z","logger":"kafkajs","message":"KafkaJS v2.0.0 switched default partitioner. To retain the same partitioning behavior as in previous versions, create the producer with the option \"createPartitioner: Partitioners.LegacyPartitioner\". See the migration guide at https://kafka.js.org/docs/migration-guide-v2.0.0#producer-new-default-partitioner for details. Silence this warning by setting the environment variable \"KAFKAJS_NO_PARTITIONER_WARNING=1\""}
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'Orders'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'Orders' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'Orders' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "userId" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "userId" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "userId" TYPE INTEGER;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "status" DROP NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "status" SET DEFAULT 'Pending';ALTER TABLE "Orders" ALTER COLUMN "status" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'Orders' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'OrderItems'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'OrderItems' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'OrderItems' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "productId" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "productId" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "productId" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "quantity" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" DROP CONSTRAINT "OrderItems_OrderId_fkey"
Executing (default): ALTER TABLE "OrderItems"  ADD FOREIGN KEY ("OrderId") REFERENCES "Orders" ("id") ON DELETE SET NULL ON UPDATE CASCADE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'OrderItems' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'ProcessedEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'ProcessedEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'ProcessedEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'ProcessedEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'DeadLetterEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'DeadLetterEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'DeadLetterEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" TYPE JSON;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" TYPE TEXT;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'DeadLetterEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
{"level":"ERROR","timestamp":"2026-02-25T10:49:59.396Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:49:59.396Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":300}
{"level":"ERROR","timestamp":"2026-02-25T10:49:59.711Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:49:59.713Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":550}
{"level":"ERROR","timestamp":"2026-02-25T10:50:00.327Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:50:00.344Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":1270}
{"level":"ERROR","timestamp":"2026-02-25T10:50:01.628Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:50:01.630Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":2984}
{"level":"ERROR","timestamp":"2026-02-25T10:50:04.635Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:50:04.637Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":6840}
{"level":"ERROR","timestamp":"2026-02-25T10:50:11.493Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:50:11.494Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":12082}
{"error":"Connection error: getaddrinfo ENOTFOUND kafka","level":"error","message":"Failed to connect Kafka producer on startup","timestamp":"2026-02-25T10:50:11.496Z"}
Server is running on port 3001
{"level":"ERROR","timestamp":"2026-02-25T10:50:11.515Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:50:11.516Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":303}
{"level":"ERROR","timestamp":"2026-02-25T10:50:11.832Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:50:11.833Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":694}
{"level":"ERROR","timestamp":"2026-02-25T10:50:12.537Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:50:12.538Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":1448}
{"level":"ERROR","timestamp":"2026-02-25T10:50:14.000Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:50:14.001Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":3236}
{"level":"ERROR","timestamp":"2026-02-25T10:50:17.249Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:50:17.250Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":4,"retryTime":5360}
{"level":"info","message":"::ffff:172.18.0.2 - - [25/Feb/2026:10:50:18 +0000] \"GET /metrics HTTP/1.1\" 200 - \"-\" \"Prometheus/3.7.1\"","timestamp":"2026-02-25T10:50:18.058Z"}
{"level":"ERROR","timestamp":"2026-02-25T10:50:22.630Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:50:22.632Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":5,"retryTime":11900}
node:internal/process/promises:288
            triggerUncaughtException(err, true /* fromPromise */);
            ^

KafkaJSNonRetriableError
  Caused by: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
    at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
    ... 3 lines matching cause stack trace ...
    at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
  name: 'KafkaJSNumberOfRetriesExceeded',
  retriable: false,
  helpUrl: undefined,
  retryCount: 5,
  retryTime: 11900,
  [cause]: KafkaJSConnectionError: Connection error: getaddrinfo ENOTFOUND kafka
      at Socket.onError (/app/node_modules/kafkajs/src/network/connection.js:210:23)
      at Socket.emit (node:events:517:28)
      at emitErrorNT (node:internal/streams/destroy:151:8)
      at emitErrorCloseNT (node:internal/streams/destroy:116:3)
      at process.processTicksAndRejections (node:internal/process/task_queues:82:21) {
    retriable: true,
    helpUrl: undefined,
    broker: 'kafka:9092',
    code: 'ENOTFOUND',
    [cause]: undefined
  }
}

Node.js v18.20.8

> order-service@1.0.0 start
> node index.js

[dotenv@17.3.1] injecting env (0) from .env -- tip: ðŸ¤– agentic secret storage: https://dotenvx.com/as2
{"level":"WARN","timestamp":"2026-02-25T10:50:23.570Z","logger":"kafkajs","message":"KafkaJS v2.0.0 switched default partitioner. To retain the same partitioning behavior as in previous versions, create the producer with the option \"createPartitioner: Partitioners.LegacyPartitioner\". See the migration guide at https://kafka.js.org/docs/migration-guide-v2.0.0#producer-new-default-partitioner for details. Silence this warning by setting the environment variable \"KAFKAJS_NO_PARTITIONER_WARNING=1\""}
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'Orders'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'Orders' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'Orders' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "userId" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "userId" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "userId" TYPE INTEGER;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "status" DROP NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "status" SET DEFAULT 'Pending';ALTER TABLE "Orders" ALTER COLUMN "status" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "Orders" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "Orders" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'Orders' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'OrderItems'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'OrderItems' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'OrderItems' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "productId" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "productId" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "productId" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "quantity" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "quantity" TYPE INTEGER;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "OrderItems" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "OrderItems" DROP CONSTRAINT "OrderItems_OrderId_fkey"
Executing (default): ALTER TABLE "OrderItems"  ADD FOREIGN KEY ("OrderId") REFERENCES "Orders" ("id") ON DELETE SET NULL ON UPDATE CASCADE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'OrderItems' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'ProcessedEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'ProcessedEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'ProcessedEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "processedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "ProcessedEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'ProcessedEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
Executing (default): SELECT table_name FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'DeadLetterEvents'
Executing (default): SELECT pk.constraint_type as "Constraint",c.column_name as "Field", c.column_default as "Default",c.is_nullable as "Null", (CASE WHEN c.udt_name = 'hstore' THEN c.udt_name ELSE c.data_type END) || (CASE WHEN c.character_maximum_length IS NOT NULL THEN '(' || c.character_maximum_length || ')' ELSE '' END) as "Type", (SELECT array_agg(e.enumlabel) FROM pg_catalog.pg_type t JOIN pg_catalog.pg_enum e ON t.oid=e.enumtypid WHERE t.typname=c.udt_name) AS "special", (SELECT pgd.description FROM pg_catalog.pg_statio_all_tables AS st INNER JOIN pg_catalog.pg_description pgd on (pgd.objoid=st.relid) WHERE c.ordinal_position=pgd.objsubid AND c.table_name=st.relname) AS "Comment" FROM information_schema.columns c LEFT JOIN (SELECT tc.table_schema, tc.table_name, cu.column_name, tc.constraint_type FROM information_schema.TABLE_CONSTRAINTS tc JOIN information_schema.KEY_COLUMN_USAGE  cu ON tc.table_schema=cu.table_schema and tc.table_name=cu.table_name and tc.constraint_name=cu.constraint_name and tc.constraint_type='PRIMARY KEY') pk ON pk.table_schema=c.table_schema AND pk.table_name=c.table_name AND pk.column_name=c.column_name WHERE c.table_name = 'DeadLetterEvents' AND c.table_schema = 'public'
Executing (default): SELECT DISTINCT tc.constraint_name as constraint_name, tc.constraint_schema as constraint_schema, tc.constraint_catalog as constraint_catalog, tc.table_name as table_name,tc.table_schema as table_schema,tc.table_catalog as table_catalog,tc.initially_deferred as initially_deferred,tc.is_deferrable as is_deferrable,kcu.column_name as column_name,ccu.table_schema  AS referenced_table_schema,ccu.table_catalog  AS referenced_table_catalog,ccu.table_name  AS referenced_table_name,ccu.column_name AS referenced_column_name FROM information_schema.table_constraints AS tc JOIN information_schema.key_column_usage AS kcu ON tc.constraint_name = kcu.constraint_name JOIN information_schema.constraint_column_usage AS ccu ON ccu.constraint_name = tc.constraint_name WHERE constraint_type = 'FOREIGN KEY' AND tc.table_name = 'DeadLetterEvents' AND tc.table_catalog = 'orders_db'
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "eventType" TYPE VARCHAR(255);
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "payload" TYPE JSON;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "errorMessage" TYPE TEXT;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "createdAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" SET NOT NULL;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" DROP DEFAULT;ALTER TABLE "DeadLetterEvents" ALTER COLUMN "updatedAt" TYPE TIMESTAMP WITH TIME ZONE;
Executing (default): SELECT i.relname AS name, ix.indisprimary AS primary, ix.indisunique AS unique, ix.indkey AS indkey, array_agg(a.attnum) as column_indexes, array_agg(a.attname) AS column_names, pg_get_indexdef(ix.indexrelid) AS definition FROM pg_class t, pg_class i, pg_index ix, pg_attribute a WHERE t.oid = ix.indrelid AND i.oid = ix.indexrelid AND a.attrelid = t.oid AND t.relkind = 'r' and t.relname = 'DeadLetterEvents' GROUP BY i.relname, ix.indexrelid, ix.indisprimary, ix.indisunique, ix.indkey ORDER BY i.relname;
{"level":"ERROR","timestamp":"2026-02-25T10:50:23.678Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:50:23.679Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":0,"retryTime":335}
{"level":"ERROR","timestamp":"2026-02-25T10:50:24.029Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:50:24.031Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":1,"retryTime":796}
{"level":"ERROR","timestamp":"2026-02-25T10:50:24.840Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:50:24.841Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":2,"retryTime":1324}
{"level":"ERROR","timestamp":"2026-02-25T10:50:26.171Z","logger":"kafkajs","message":"[Connection] Connection error: getaddrinfo ENOTFOUND kafka","broker":"kafka:9092","clientId":"kafkajs","stack":"Error: getaddrinfo ENOTFOUND kafka\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (node:dns:107:26)"}
{"level":"ERROR","timestamp":"2026-02-25T10:50:26.172Z","logger":"kafkajs","message":"[BrokerPool] Failed to connect to seed broker, trying another broker from the list: Connection error: getaddrinfo ENOTFOUND kafka","retryCount":3,"retryTime":2654}
